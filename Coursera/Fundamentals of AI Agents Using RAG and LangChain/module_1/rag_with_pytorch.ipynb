{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Updated RAG with PyTorch Implementation of the Course Notebook\n",
    "* Tokenizer and Model Loading: The code uses torch.hub.load, which is outdated. Hugging Face’s transformers library now recommends AutoTokenizer and AutoModel for standardized loading.\n",
    "* Device Handling: Device management is present but can be streamlined with a single device variable for consistency and flexibility (CPU/GPU support).\n",
    "* Embedding Generation: The aggregate_embeddings function manually computes mean embeddings, which is inefficient. Modern BERT models allow simpler mean pooling directly from outputs.\n",
    "* Similarity Calculation: The dot product is used, but cosine similarity is more appropriate for embeddings as it focuses on direction rather than magnitude (as suggested by the exercise).\n",
    "* Data Preprocessing: The process_song function is basic and can be enhanced with additional text cleaning steps.\n",
    "* Visualization: The t-SNE plotting function uses suboptimal perplexity settings and could improve clarity with better labeling and color mapping.\n",
    "* Code Structure: Some functions (e.g., text_to_emb) can be simplified by leveraging Hugging Face’s batch processing capabilities.\n"
   ],
   "id": "92f7e1d1dc093083"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install --user numpy torch transformers matplotlib scikit-learn tqdm --upgrade",
   "id": "9815de0cd1cf7807"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T14:17:53.930434Z",
     "start_time": "2025-03-31T14:17:49.068268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')"
   ],
   "id": "a429167ae791f886",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Explanation:\n",
    "\n",
    "* Added AutoTokenizer and AutoModel from transformers to replace torch.hub usage.\n",
    "* Introduced a device variable for consistent GPU/CPU handling across the notebook.\n",
    "* Kept tqdm, numpy, torch, TSNE, and matplotlib as they’re still needed.\n",
    "* Retained warning suppression for cleaner output but removed the custom warn function (unnecessary with filterwarnings)."
   ],
   "id": "a1e13f0a3413e9ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T14:18:01.648337Z",
     "start_time": "2025-03-31T14:17:56.052435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "id": "dfab8effcf04896b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. Loading Tokenizer and Model",
   "id": "4e8df8ae88dbf12f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T14:19:24.535781Z",
     "start_time": "2025-03-31T14:19:18.484956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load tokenizer and model using Auto classes\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = AutoModel.from_pretrained(\"bert-base-uncased\").to(device)"
   ],
   "id": "1d8af5c11b03ae4f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Explanation:\n",
    "\n",
    "* Replaced torch.hub.load with AutoTokenizer and AutoModel from transformers, which are the current standards for loading pretrained models.\n",
    "* Used from_pretrained to fetch \"bert-base-uncased\" directly from Hugging Face’s model hub.\n",
    "* Moved the model to device (defined earlier) for GPU support, improving performance on compatible hardware."
   ],
   "id": "d17818de570e68ba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4. Generating Embeddings",
   "id": "c75339672dc0b40b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T14:34:31.238134Z",
     "start_time": "2025-03-31T14:34:31.154853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def text_to_emb(texts, max_length=512):\n",
    "    \"\"\"Convert list of texts to mean-pooled embeddings.\"\"\"\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    # Mean pooling over the sequence length dimension\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings\n",
    "\n",
    "# Example usage\n",
    "input_text = [\"This is an example sentence for BERT embeddings.\", \"How do you like it?\"]\n",
    "embeddings = text_to_emb(input_text)\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "\n",
    "\"\"\"\n",
    "Output: Returns a tensor of shape [batch_size, hidden_size] (e.g., [2, 768] for two sentences with BERT’s 768-dimensional embeddings).\n",
    "\"\"\""
   ],
   "id": "f7577b8110b384f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: torch.Size([2, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nOutput: Returns a tensor of shape [batch_size, hidden_size] (e.g., [2, 768] for two sentences with BERT’s 768-dimensional embeddings).\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5. Preprocessing Song Lyrics",
   "id": "fadcb1aadb90a2a0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T14:34:33.335463Z",
     "start_time": "2025-03-31T14:34:33.328003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "def process_song(song):\n",
    "    \"\"\"Clean and preprocess song lyrics.\"\"\"\n",
    "    # Remove line breaks and extra spaces\n",
    "    song = re.sub(r'\\n+', ' ', song).strip()\n",
    "    # Remove special characters and punctuation (optional)\n",
    "    song = re.sub(r'[^a-zA-Z0-9\\s]', '', song)\n",
    "    return [song]  # Return as a list for consistency with text_to_emb"
   ],
   "id": "2b5325fb82fa6c0a",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 6. Generating Embeddings for Questions and Songs",
   "id": "8fd754f0738b7a30"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T14:34:35.918082Z",
     "start_time": "2025-03-31T14:34:35.693742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sesame_street = \"\"\"\n",
    "Sunny day\n",
    "Sweepin' the clouds away\n",
    "On my way to where the air is sweet\n",
    "Can you tell me how to get\n",
    "How to get to Sesame Street?\n",
    "\n",
    "Come and play\n",
    "Everything's A-okay\n",
    "Friendly neighbors there\n",
    "That's where we meet\n",
    "Can you tell me how to get\n",
    "How to get to Sesame Street?\n",
    "\n",
    "It's a magic carpet ride\n",
    "Every door will open wide\n",
    "To happy people like you\n",
    "Happy people like\n",
    "What a beautiful\n",
    "\n",
    "Sunny day\n",
    "Sweepin' the clouds away\n",
    "On my way to where the air is sweet\n",
    "Can you tell me how to get\n",
    "How to get to Sesame Street?\n",
    "How to get to Sesame Street?\n",
    "How to get to Sesame Street?\n",
    "How to get to Sesame Street?\n",
    "How to get to Sesame Street?\n",
    "\"\"\"\n",
    "# Predefined questions (unchanged from original)\n",
    "song_questions = [\n",
    "    \"Does this song contain any violent themes, such as references to guns, killing, or physical aggression? ...\",\n",
    "    # ... (rest of the questions remain the same)\n",
    "]\n",
    "\n",
    "# Convert questions to embeddings\n",
    "embeddings_questions = text_to_emb(song_questions)\n",
    "\n",
    "# Process and embed songs (example with song_rage and sesame_street)\n",
    "# song_rage = process_song(song_rage)  # song_rage lyrics should be provided\n",
    "# embeddings_rage = text_to_emb(song_rage)\n",
    "\n",
    "song_sesame_street = process_song(sesame_street)\n",
    "embeddings_sesame_street = text_to_emb(song_sesame_street)\n"
   ],
   "id": "461fea95735c4d3f",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 7. Similarity Calculation: Cosine Similarity",
   "id": "9f3cfa00c83f44b0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T14:34:39.074785Z",
     "start_time": "2025-03-31T14:34:38.994728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "yes_responses = [\n",
    "    \"Yes, this song contains violent themes, including references to guns, killing, or physical aggression, and is not suitable for children.\",\n",
    "    \"Yes, this song includes explicit lyrics or bad words that might be considered offensive or inappropriate for young audiences.\",\n",
    "    \"No, the overall content of this song is not suitable for children as it includes themes, language, and messages that are too mature or unsuitable for young listeners.\",\n",
    "    \"Yes, this song explicitly mentions weapons, such as guns and knives, which could be disturbing or inappropriate for children’s entertainment.\",\n",
    "    \"Yes, the messages conveyed in this song are positive and uplifting, promoting values like kindness, friendship, and positivity, beneficial for children.\",\n",
    "    \"Yes, this song includes sexual content and references to sexual behavior or suggestive language, which are inappropriate for a child-friendly environment.\",\n",
    "    \"Yes, this song offers significant educational value, including segments that teach the alphabet, basic math, and other learning content, making it both fun and educational for children.\",\n",
    "    \"Yes, this song promotes emotional resilience and social skills, incorporating themes about overcoming challenges and building friendships, which are essential for children's development.\"\n",
    "]\n",
    "\n",
    "from torch.nn.functional import cosine_similarity\n",
    "\n",
    "def RAG_QA(embeddings_questions, embeddings, n_responses=3):\n",
    "    \"\"\"Find top responses using cosine similarity.\"\"\"\n",
    "    # Compute cosine similarity between questions and song embeddings\n",
    "    similarities = cosine_similarity(embeddings_questions, embeddings)\n",
    "    similarities = similarities.squeeze()  # Remove extra dimensions if embeddings is a single vector\n",
    "    # Get top n indices\n",
    "    top_indices = torch.argsort(similarities, descending=True)[:n_responses]\n",
    "    for idx in top_indices:\n",
    "        print(yes_responses[idx.item()])\n",
    "\n",
    "# Example usage\n",
    "# print(\"Rage Against the Machine - Bullet in the Head:\")\n",
    "# RAG_QA(embeddings_questions, embeddings_rage)\n",
    "print(\"\\nSesame Street Theme:\")\n",
    "RAG_QA(embeddings_questions, embeddings_sesame_street)"
   ],
   "id": "deea174c49cd361c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sesame Street Theme:\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "slice() cannot be applied to a 0-dim tensor.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[20], line 28\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m# Example usage\u001B[39;00m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;66;03m# print(\"Rage Against the Machine - Bullet in the Head:\")\u001B[39;00m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;66;03m# RAG_QA(embeddings_questions, embeddings_rage)\u001B[39;00m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mSesame Street Theme:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 28\u001B[0m \u001B[43mRAG_QA\u001B[49m\u001B[43m(\u001B[49m\u001B[43membeddings_questions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membeddings_sesame_street\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[20], line 20\u001B[0m, in \u001B[0;36mRAG_QA\u001B[1;34m(embeddings_questions, embeddings, n_responses)\u001B[0m\n\u001B[0;32m     18\u001B[0m similarities \u001B[38;5;241m=\u001B[39m similarities\u001B[38;5;241m.\u001B[39msqueeze()  \u001B[38;5;66;03m# Remove extra dimensions if embeddings is a single vector\u001B[39;00m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# Get top n indices\u001B[39;00m\n\u001B[1;32m---> 20\u001B[0m top_indices \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margsort\u001B[49m\u001B[43m(\u001B[49m\u001B[43msimilarities\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdescending\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43mn_responses\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m top_indices:\n\u001B[0;32m     22\u001B[0m     \u001B[38;5;28mprint\u001B[39m(yes_responses[idx\u001B[38;5;241m.\u001B[39mitem()])\n",
      "\u001B[1;31mIndexError\u001B[0m: slice() cannot be applied to a 0-dim tensor."
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 8. Visualization with t-SNE",
   "id": "aa61cda63abeb8e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T14:34:04.154293Z",
     "start_time": "2025-03-31T14:34:03.876022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tsne_plot(data, plot_title):\n",
    "    \"\"\"Visualize embeddings in 3D using t-SNE.\"\"\"\n",
    "    tsne = TSNE(n_components=3, random_state=42, perplexity=min(30, data.shape[0] - 1))\n",
    "    data_3d = tsne.fit_transform(data.cpu().numpy())  # Convert to numpy if on GPU\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    scatter = ax.scatter(data_3d[:, 0], data_3d[:, 1], data_3d[:, 2], c=range(len(data_3d)), cmap='viridis')\n",
    "    ax.set_title(f'3D t-SNE Visualization of {plot_title} Embeddings')\n",
    "    ax.set_xlabel('TSNE Component 1')\n",
    "    ax.set_ylabel('TSNE Component 2')\n",
    "    ax.set_zlabel('TSNE Component 3')\n",
    "    plt.colorbar(scatter, label='Index')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "tsne_plot(embeddings_questions, \"Question\")"
   ],
   "id": "988ba83cda34257d",
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'perplexity' parameter of TSNE must be a float in the range (0.0, inf). Got 0 instead.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidParameterError\u001B[0m                     Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 16\u001B[0m\n\u001B[0;32m     13\u001B[0m     plt\u001B[38;5;241m.\u001B[39mshow()\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# Example usage\u001B[39;00m\n\u001B[1;32m---> 16\u001B[0m \u001B[43mtsne_plot\u001B[49m\u001B[43m(\u001B[49m\u001B[43membeddings_questions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mQuestion\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[16], line 4\u001B[0m, in \u001B[0;36mtsne_plot\u001B[1;34m(data, plot_title)\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Visualize embeddings in 3D using t-SNE.\"\"\"\u001B[39;00m\n\u001B[0;32m      3\u001B[0m tsne \u001B[38;5;241m=\u001B[39m TSNE(n_components\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m, perplexity\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mmin\u001B[39m(\u001B[38;5;241m30\u001B[39m, data\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m----> 4\u001B[0m data_3d \u001B[38;5;241m=\u001B[39m \u001B[43mtsne\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcpu\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Convert to numpy if on GPU\u001B[39;00m\n\u001B[0;32m      5\u001B[0m fig \u001B[38;5;241m=\u001B[39m plt\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m7\u001B[39m))\n\u001B[0;32m      6\u001B[0m ax \u001B[38;5;241m=\u001B[39m fig\u001B[38;5;241m.\u001B[39madd_subplot(\u001B[38;5;241m111\u001B[39m, projection\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m3d\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\panaversity\\lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001B[0m, in \u001B[0;36m_wrap_method_output.<locals>.wrapped\u001B[1;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[0;32m    317\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[0;32m    318\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m--> 319\u001B[0m     data_to_wrap \u001B[38;5;241m=\u001B[39m f(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    320\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m    321\u001B[0m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[0;32m    322\u001B[0m         return_tuple \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    323\u001B[0m             _wrap_data_with_container(method, data_to_wrap[\u001B[38;5;241m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[0;32m    324\u001B[0m             \u001B[38;5;241m*\u001B[39mdata_to_wrap[\u001B[38;5;241m1\u001B[39m:],\n\u001B[0;32m    325\u001B[0m         )\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\panaversity\\lib\\site-packages\\sklearn\\base.py:1382\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1377\u001B[0m partial_fit_and_fitted \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m   1378\u001B[0m     fit_method\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpartial_fit\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m _is_fitted(estimator)\n\u001B[0;32m   1379\u001B[0m )\n\u001B[0;32m   1381\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m global_skip_validation \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m partial_fit_and_fitted:\n\u001B[1;32m-> 1382\u001B[0m     \u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_params\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1384\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1385\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1386\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1387\u001B[0m     )\n\u001B[0;32m   1388\u001B[0m ):\n\u001B[0;32m   1389\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\panaversity\\lib\\site-packages\\sklearn\\base.py:436\u001B[0m, in \u001B[0;36mBaseEstimator._validate_params\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    428\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_validate_params\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    429\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Validate types and values of constructor parameters\u001B[39;00m\n\u001B[0;32m    430\u001B[0m \n\u001B[0;32m    431\u001B[0m \u001B[38;5;124;03m    The expected type and values must be defined in the `_parameter_constraints`\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    434\u001B[0m \u001B[38;5;124;03m    accepted constraints.\u001B[39;00m\n\u001B[0;32m    435\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 436\u001B[0m     \u001B[43mvalidate_parameter_constraints\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    437\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_parameter_constraints\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    438\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_params\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdeep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    439\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcaller_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__class__\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__name__\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    440\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\panaversity\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:98\u001B[0m, in \u001B[0;36mvalidate_parameter_constraints\u001B[1;34m(parameter_constraints, params, caller_name)\u001B[0m\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     93\u001B[0m     constraints_str \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     94\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin([\u001B[38;5;28mstr\u001B[39m(c)\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mc\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39mconstraints[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m or\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     95\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconstraints[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     96\u001B[0m     )\n\u001B[1;32m---> 98\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m InvalidParameterError(\n\u001B[0;32m     99\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mparam_name\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m parameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcaller_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    100\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconstraints_str\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mparam_val\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    101\u001B[0m )\n",
      "\u001B[1;31mInvalidParameterError\u001B[0m: The 'perplexity' parameter of TSNE must be a float in the range (0.0, inf). Got 0 instead."
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5996e60b066d625b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
