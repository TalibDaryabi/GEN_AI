{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-31T13:00:10.914039Z",
     "start_time": "2025-03-31T13:00:07.123067Z"
    }
   },
   "source": [
    "# Install the latest compatible versions of required libraries\n",
    "!pip install  --user transformers datasets torch faiss-cpu wget matplotlib scikit-learn --upgrade"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\talib\\appdata\\roaming\\python\\python310\\site-packages (4.50.3)\n",
      "Requirement already satisfied: datasets in c:\\users\\talib\\appdata\\roaming\\python\\python310\\site-packages (3.5.0)\n",
      "Requirement already satisfied: torch in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\talib\\appdata\\roaming\\python\\python310\\site-packages (1.10.0)\n",
      "Requirement already satisfied: wget in c:\\users\\talib\\appdata\\roaming\\python\\python310\\site-packages (3.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\talib\\appdata\\roaming\\python\\python310\\site-packages (3.10.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from transformers) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from datasets) (3.11.12)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\talib\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\talib\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\talib\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\talib\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\talib\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\talib\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from pandas->datasets) (2025.1)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:00:19.480246Z",
     "start_time": "2025-03-31T13:00:16.053219Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install wget\n",
   "id": "4bf0584179ac39b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in c:\\users\\talib\\appdata\\roaming\\python\\python310\\site-packages (3.2)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:02:10.726098Z",
     "start_time": "2025-03-31T13:01:49.426797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer\n",
    "from transformers import DPRQuestionEncoder, DPRQuestionEncoderTokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import faiss\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Set device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "id": "bcdab936c17cf373",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:02:24.924022Z",
     "start_time": "2025-03-31T13:02:24.911023Z"
    }
   },
   "cell_type": "code",
   "source": "import wget",
   "id": "d11e1c6370237d82",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load and Preprocess Data",
   "id": "b7ccd7e42ee4f356"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:02:32.285778Z",
     "start_time": "2025-03-31T13:02:31.276189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def read_and_split_text(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    # Split by two newlines for more accurate paragraph detection\n",
    "    paragraphs = text.split('\\n\\n')\n",
    "    # Filter out empty or short paragraphs\n",
    "    paragraphs = [para.strip() for para in paragraphs if len(para.strip()) > 10]\n",
    "    return paragraphs\n",
    "\n",
    "filename = 'companyPolicies.txt'\n",
    "url = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/6JDbUb_L3egv_eOkouY71A.txt'\n",
    "wget.download(url, out=filename)\n",
    "print('File downloaded')\n",
    "\n",
    "paragraphs = read_and_split_text(filename)\n",
    "for i in range(4):\n",
    "    print(f\"Sample {i}: {paragraphs[i]}\\n\")"
   ],
   "id": "c41b352b94fb8eaa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded\n",
      "Sample 0: 1.\tCode of Conduct\n",
      "\n",
      "Sample 1: Our Code of Conduct outlines the fundamental principles and ethical standards that guide every member of our organization. We are committed to maintaining a workplace that is built on integrity, respect, and accountability.\n",
      "Integrity: We hold ourselves to the highest ethical standards. This means acting honestly and transparently in all our interactions, whether with colleagues, clients, or the broader community. We respect and protect sensitive information, and we avoid conflicts of interest.\n",
      "Respect: We embrace diversity and value each individual's contributions. Discrimination, harassment, or any form of disrespectful behavior is unacceptable. We create an inclusive environment where differences are celebrated and everyone is treated with dignity and courtesy.\n",
      "Accountability: We take responsibility for our actions and decisions. We follow all relevant laws and regulations, and we strive to continuously improve our practices. We report any potential violations of this code and support the investigation of such matters.\n",
      "Safety: We prioritize the safety of our employees, clients, and the communities we serve. We maintain a culture of safety, including reporting any unsafe conditions or practices.\n",
      "Environmental Responsibility: We are committed to minimizing our environmental footprint and promoting sustainable practices.\n",
      "Our Code of Conduct is not just a set of rules; it is the foundation of our organization's culture. We expect all employees to uphold these principles and serve as role models for others, ensuring we maintain our reputation for ethical conduct, integrity, and social responsibility.\n",
      "\n",
      "Sample 2: 2.\tRecruitment Policy\n",
      "\n",
      "Sample 3: Our Recruitment Policy reflects our commitment to attracting, selecting, and onboarding the most qualified and diverse candidates to join our organization. We believe that the success of our company relies on the talents, skills, and dedication of our employees.\n",
      "Equal Opportunity: We are an equal opportunity employer and do not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, or any other protected status. We actively promote diversity and inclusion.\n",
      "Transparency: We maintain transparency in our recruitment processes. All job vacancies are advertised internally and externally when appropriate. Job descriptions and requirements are clear and accurately represent the role.\n",
      "Selection Criteria: Our selection process is based on the qualifications, experience, and skills necessary for the position. Interviews and assessments are conducted objectively, and decisions are made without bias.\n",
      "Data Privacy: We are committed to protecting the privacy of candidates' personal information and adhere to all relevant data protection laws and regulations.\n",
      "Feedback: Candidates will receive timely and constructive feedback on their application and interview performance.\n",
      "Onboarding: New employees receive comprehensive onboarding to help them integrate into the organization effectively. This includes information on our culture, policies, and expectations.\n",
      "Employee Referrals: We encourage and appreciate employee referrals as they contribute to building a strong and engaged team.\n",
      "Our Recruitment Policy is a foundation for creating a diverse, inclusive, and talented workforce. It ensures that we attract and hire the best candidates who align with our company values and contribute to our continued success. We continuously review and update this policy to reflect evolving best practices in recruitment.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Building the Retriever: Encoding and Indexing\n",
    "### Explaination\n",
    "\n",
    "**Batch Processing**: Processes texts in batches (default batch_size=32),reducing computation time significantly compared to one-by-one encoding.\n",
    "\n",
    "**Device Support**: Moves inputs and models to the GPU (to(device)), leveraging hardware acceleration.\n",
    "\n",
    "**Memory Efficiency**: Uses torch.no_grad() to disable gradient computation during inference"
   ],
   "id": "e59237497657d72a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:06:28.102222Z",
     "start_time": "2025-03-31T13:05:39.988179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load DPR context encoder and tokenizer\n",
    "context_tokenizer = DPRContextEncoderTokenizer.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n",
    "context_encoder = DPRContextEncoder.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base').to(device)\n",
    "\n",
    "def encode_contexts(text_list, batch_size=32):\n",
    "    \"\"\"Encode a list of texts into embeddings with batch processing.\"\"\"\n",
    "    embeddings = []\n",
    "    for i in range(0, len(text_list), batch_size):\n",
    "        batch_texts = text_list[i:i + batch_size]\n",
    "        inputs = context_tokenizer(batch_texts, return_tensors='pt', padding=True, truncation=True, max_length=256).to(device)\n",
    "        with torch.no_grad():  # Reduce memory usage during inference\n",
    "            outputs = context_encoder(**inputs)\n",
    "        embeddings.append(outputs.pooler_output.cpu())  # Move to CPU for FAISS compatibility\n",
    "    return torch.cat(embeddings).numpy()\n",
    "\n",
    "# Shuffle and encode paragraphs\n",
    "random.shuffle(paragraphs)\n",
    "context_embeddings = encode_contexts(paragraphs)\n",
    "\n",
    "# Create FAISS index\n",
    "embedding_dim = 768\n",
    "context_embeddings_np = np.array(context_embeddings).astype('float32')\n",
    "index = faiss.IndexFlatL2(embedding_dim)\n",
    "index.add(context_embeddings_np)\n",
    "print(f\"FAISS index created with {index.ntotal} embeddings\")"
   ],
   "id": "247089ee0cbc53b7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizer'.\n",
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index created with 18 embeddings\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# DPR Question Encoder and Tokenizer",
   "id": "5ec1c2e6ef8b21a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:12:14.481064Z",
     "start_time": "2025-03-31T13:11:31.263484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "question_encoder = DPRQuestionEncoder.from_pretrained('facebook/dpr-question_encoder-single-nq-base').to(device)\n",
    "question_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n",
    "\n",
    "def search_relevant_contexts(question, k=5):\n",
    "    \"\"\"Search for relevant contexts using DPR and FAISS.\"\"\"\n",
    "    question_inputs = question_tokenizer(question, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        question_embedding = question_encoder(**question_inputs).pooler_output.cpu().numpy()\n",
    "    D, I = index.search(question_embedding, k)\n",
    "    return D, I\n",
    "\n",
    "# Example usage\n",
    "question = \"What is the mobile policy?\"\n",
    "D, I = search_relevant_contexts(question)\n",
    "print(\"Top 5 relevant contexts:\")\n",
    "for i, idx in enumerate(I[0]):\n",
    "    print(f\"{i+1}: {paragraphs[idx]} (Distance: {D[0][i]:.4f})\")"
   ],
   "id": "1d3ab66e4448255a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/dpr-question_encoder-single-nq-base were not used when initializing DPRQuestionEncoder: ['question_encoder.bert_model.pooler.dense.bias', 'question_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRQuestionEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRQuestionEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 relevant contexts:\n",
      "1: 4.\tMobile Phone Policy (Distance: 72.1663)\n",
      "2: 9.\tDiscipline and Termination Policy (Distance: 83.6451)\n",
      "3: 3.\tInternet and Email Policy (Distance: 86.6923)\n",
      "4: The Mobile Phone Policy sets forth the standards and expectations governing the appropriate and responsible usage of mobile devices in the organization. The purpose of this policy is to ensure that employees utilize mobile phones in a manner consistent with company values and legal compliance.\n",
      "Acceptable Use: Mobile devices are primarily intended for work-related tasks. Limited personal usage is allowed, provided it does not disrupt work obligations.\n",
      "Security: Safeguard your mobile device and access credentials. Exercise caution when downloading apps or clicking links from unfamiliar sources. Promptly report security concerns or suspicious activities related to your mobile device.\n",
      "Confidentiality: Avoid transmitting sensitive company information via unsecured messaging apps or emails. Be discreet when discussing company matters in public spaces.\n",
      "Cost Management: Keep personal phone usage separate from company accounts and reimburse the company for any personal charges on company-issued phones.\n",
      "Compliance: Adhere to all pertinent laws and regulations concerning mobile phone usage, including those related to data protection and privacy.\n",
      "Lost or Stolen Devices: Immediately report any lost or stolen mobile devices to the IT department or your supervisor.\n",
      "Consequences: Non-compliance with this policy may lead to disciplinary actions, including the potential loss of mobile phone privileges.\n",
      "The Mobile Phone Policy is aimed at promoting the responsible and secure use of mobile devices in line with legal and ethical standards. Every employee is expected to comprehend and abide by these guidelines. Regular reviews of the policy ensure its ongoing alignment with evolving technology and security best practices. (Distance: 89.8481)\n",
      "5: 2.\tRecruitment Policy (Distance: 93.0869)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Enhancing Response Generation with LLMs",
   "id": "10cb0aaa0403e999"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:15:37.296491Z",
     "start_time": "2025-03-31T13:14:33.302331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\").to(device)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Set pad token explicitly for GPT-2\n",
    "\n",
    "def generate_answer(question, contexts):\n",
    "    \"\"\"Generate an answer using a structured prompt.\"\"\"\n",
    "    input_text = f\"Question: {question}\\nContexts: {' '.join(contexts)}\\nAnswer:\"\n",
    "    print(f\"Input text: {input_text}\")  # For debugging\n",
    "    inputs = tokenizer(input_text, return_tensors='pt', max_length=1024, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        summary_ids = model.generate(\n",
    "            inputs['input_ids'],\n",
    "            max_new_tokens=50,\n",
    "            min_length=40,\n",
    "            length_penalty=2.0,\n",
    "            num_beams=4,\n",
    "            early_stopping=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "def generate_answer_without_context(question):\n",
    "    \"\"\"Generate an answer without contexts.\"\"\"\n",
    "    inputs = tokenizer(question, return_tensors='pt', max_length=1024, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        summary_ids = model.generate(\n",
    "            inputs['input_ids'],\n",
    "            max_new_tokens=150,\n",
    "            min_length=40,\n",
    "            length_penalty=2.0,\n",
    "            num_beams=4,\n",
    "            early_stopping=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Example comparison\n",
    "question = \"What is the mobile policy?\"\n",
    "_, I = search_relevant_contexts(question)\n",
    "top_contexts = [paragraphs[idx] for idx in I[0]]\n",
    "print(\"With DPR contexts:\")\n",
    "print(generate_answer(question, top_contexts))\n",
    "print(\"\\nWithout DPR contexts:\")\n",
    "print(generate_answer_without_context(question))"
   ],
   "id": "f9aaee8a70aa3459",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With DPR contexts:\n",
      "Input text: Question: What is the mobile policy?\n",
      "Contexts: 4.\tMobile Phone Policy 9.\tDiscipline and Termination Policy 3.\tInternet and Email Policy The Mobile Phone Policy sets forth the standards and expectations governing the appropriate and responsible usage of mobile devices in the organization. The purpose of this policy is to ensure that employees utilize mobile phones in a manner consistent with company values and legal compliance.\n",
      "Acceptable Use: Mobile devices are primarily intended for work-related tasks. Limited personal usage is allowed, provided it does not disrupt work obligations.\n",
      "Security: Safeguard your mobile device and access credentials. Exercise caution when downloading apps or clicking links from unfamiliar sources. Promptly report security concerns or suspicious activities related to your mobile device.\n",
      "Confidentiality: Avoid transmitting sensitive company information via unsecured messaging apps or emails. Be discreet when discussing company matters in public spaces.\n",
      "Cost Management: Keep personal phone usage separate from company accounts and reimburse the company for any personal charges on company-issued phones.\n",
      "Compliance: Adhere to all pertinent laws and regulations concerning mobile phone usage, including those related to data protection and privacy.\n",
      "Lost or Stolen Devices: Immediately report any lost or stolen mobile devices to the IT department or your supervisor.\n",
      "Consequences: Non-compliance with this policy may lead to disciplinary actions, including the potential loss of mobile phone privileges.\n",
      "The Mobile Phone Policy is aimed at promoting the responsible and secure use of mobile devices in line with legal and ethical standards. Every employee is expected to comprehend and abide by these guidelines. Regular reviews of the policy ensure its ongoing alignment with evolving technology and security best practices. 2.\tRecruitment Policy\n",
      "Answer:\n",
      "Question: What is the mobile policy?\n",
      "Contexts: 4.\tMobile Phone Policy 9.\tDiscipline and Termination Policy 3.\tInternet and Email Policy The Mobile Phone Policy sets forth the standards and expectations governing the appropriate and responsible usage of mobile devices in the organization. The purpose of this policy is to ensure that employees utilize mobile phones in a manner consistent with company values and legal compliance.\n",
      "Acceptable Use: Mobile devices are primarily intended for work-related tasks. Limited personal usage is allowed, provided it does not disrupt work obligations.\n",
      "Security: Safeguard your mobile device and access credentials. Exercise caution when downloading apps or clicking links from unfamiliar sources. Promptly report security concerns or suspicious activities related to your mobile device.\n",
      "Confidentiality: Avoid transmitting sensitive company information via unsecured messaging apps or emails. Be discreet when discussing company matters in public spaces.\n",
      "Cost Management: Keep personal phone usage separate from company accounts and reimburse the company for any personal charges on company-issued phones.\n",
      "Compliance: Adhere to all pertinent laws and regulations concerning mobile phone usage, including those related to data protection and privacy.\n",
      "Lost or Stolen Devices: Immediately report any lost or stolen mobile devices to the IT department or your supervisor.\n",
      "Consequences: Non-compliance with this policy may lead to disciplinary actions, including the potential loss of mobile phone privileges.\n",
      "The Mobile Phone Policy is aimed at promoting the responsible and secure use of mobile devices in line with legal and ethical standards. Every employee is expected to comprehend and abide by these guidelines. Regular reviews of the policy ensure its ongoing alignment with evolving technology and security best practices. 2.\tRecruitment Policy\n",
      "Answer: What is the Mobile Phone Recruitment Policy? The Mobile Phone Recruitment Policy sets forth the standards and expectations governing the appropriate and responsible use of mobile devices in the organization. The purpose of this policy is to ensure that employees utilize mobile phones in\n",
      "\n",
      "Without DPR contexts:\n",
      "What is the mobile policy?\n",
      "\n",
      "The mobile policy is a set of rules that govern the use of mobile phones. The mobile policy is a set of rules that govern the use of mobile phones. The mobile policy is a set of rules that govern the use of mobile phones. The mobile policy is a set of rules that govern the use of mobile phones. The mobile policy is a set of rules that govern the use of mobile phones. The mobile policy is a set of rules that govern the use of mobile phones. The mobile policy is a set of rules that govern the use of mobile phones. The mobile policy is a set of rules that govern the use of mobile phones. The mobile policy is a set of rules that govern the use of mobile phones. The mobile policy is\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Exercise: Tuning Generation Parameters",
   "id": "d10a0024ab774f0e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:33:37.948026Z",
     "start_time": "2025-03-31T13:33:17.038230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_answer_tuned(contexts, max_new_tokens=50, min_length=40, length_penalty=2.0, num_beams=4, temperature=1.0):\n",
    "    \"\"\"Generate an answer with tunable parameters.\"\"\"\n",
    "    input_text = f\"Question: {question}\\nContexts: {' '.join(contexts)}\\nAnswer:\"\n",
    "    inputs = tokenizer(input_text, return_tensors='pt', max_length=1024, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        summary_ids = model.generate(\n",
    "            inputs['input_ids'],\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            min_length=min_length,\n",
    "            length_penalty=length_penalty,\n",
    "            num_beams=num_beams,\n",
    "            temperature=temperature,  # Controls randomness\n",
    "            early_stopping=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Parameter sets to test\n",
    "settings = [\n",
    "    {\"max_new_tokens\": 50, \"min_length\": 50, \"length_penalty\": 1.0, \"num_beams\": 2, \"temperature\": 0.7},  # Concise, less random\n",
    "    {\"max_new_tokens\": 120, \"min_length\": 30, \"length_penalty\": 2.0, \"num_beams\": 4, \"temperature\": 1.0},  # Balanced\n",
    "    {\"max_new_tokens\": 100, \"min_length\": 20, \"length_penalty\": 2.5, \"num_beams\": 6, \"temperature\": 1.2}   # Detailed, more creative\n",
    "]\n",
    "\n",
    "print(\"Exercise: Tuning Generation Parameters\")\n",
    "print(\"Try adjusting these parameters to see their effects:\")\n",
    "print(\"- max_new_tokens: Maximum length of the generated answer.\")\n",
    "print(\"- min_length: Minimum length to enforce.\")\n",
    "print(\"- length_penalty: Higher values favor shorter outputs (>1), lower values favor longer (<1).\")\n",
    "print(\"- num_beams: More beams improve quality but slow down generation.\")\n",
    "print(\"- temperature: Lower (<1) makes output more focused, higher (>1) increases diversity.\\n\")\n",
    "\n",
    "for setting in settings:\n",
    "    answer = generate_answer_tuned(top_contexts, **setting)\n",
    "    print(f\"Settings: {setting}\")\n",
    "    print(f\"Generated Answer: {answer}\\n{'='*80}\\n\")"
   ],
   "id": "fd543eae4c9fb802",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise: Tuning Generation Parameters\n",
      "Try adjusting these parameters to see their effects:\n",
      "- max_new_tokens: Maximum length of the generated answer.\n",
      "- min_length: Minimum length to enforce.\n",
      "- length_penalty: Higher values favor shorter outputs (>1), lower values favor longer (<1).\n",
      "- num_beams: More beams improve quality but slow down generation.\n",
      "- temperature: Lower (<1) makes output more focused, higher (>1) increases diversity.\n",
      "\n",
      "Settings: {'max_new_tokens': 50, 'min_length': 50, 'length_penalty': 1.0, 'num_beams': 2, 'temperature': 0.7}\n",
      "Generated Answer: Question: What is the mobile policy?\n",
      "Contexts: 4.\tMobile Phone Policy 9.\tDiscipline and Termination Policy 3.\tInternet and Email Policy The Mobile Phone Policy sets forth the standards and expectations governing the appropriate and responsible usage of mobile devices in the organization. The purpose of this policy is to ensure that employees utilize mobile phones in a manner consistent with company values and legal compliance.\n",
      "Acceptable Use: Mobile devices are primarily intended for work-related tasks. Limited personal usage is allowed, provided it does not disrupt work obligations.\n",
      "Security: Safeguard your mobile device and access credentials. Exercise caution when downloading apps or clicking links from unfamiliar sources. Promptly report security concerns or suspicious activities related to your mobile device.\n",
      "Confidentiality: Avoid transmitting sensitive company information via unsecured messaging apps or emails. Be discreet when discussing company matters in public spaces.\n",
      "Cost Management: Keep personal phone usage separate from company accounts and reimburse the company for any personal charges on company-issued phones.\n",
      "Compliance: Adhere to all pertinent laws and regulations concerning mobile phone usage, including those related to data protection and privacy.\n",
      "Lost or Stolen Devices: Immediately report any lost or stolen mobile devices to the IT department or your supervisor.\n",
      "Consequences: Non-compliance with this policy may lead to disciplinary actions, including the potential loss of mobile phone privileges.\n",
      "The Mobile Phone Policy is aimed at promoting the responsible and secure use of mobile devices in line with legal and ethical standards. Every employee is expected to comprehend and abide by these guidelines. Regular reviews of the policy ensure its ongoing alignment with evolving technology and security best practices. 2.\tRecruitment Policy\n",
      "Answer: What is the Mobile Phone Recruitment Policy? The Mobile Phone Recruitment Policy sets forth the standards and expectations governing the appropriate and responsible use of mobile devices in the organization. The purpose of this policy is to ensure that employees utilize mobile phones in\n",
      "================================================================================\n",
      "\n",
      "Settings: {'max_new_tokens': 120, 'min_length': 30, 'length_penalty': 2.0, 'num_beams': 4, 'temperature': 1.0}\n",
      "Generated Answer: Question: What is the mobile policy?\n",
      "Contexts: 4.\tMobile Phone Policy 9.\tDiscipline and Termination Policy 3.\tInternet and Email Policy The Mobile Phone Policy sets forth the standards and expectations governing the appropriate and responsible usage of mobile devices in the organization. The purpose of this policy is to ensure that employees utilize mobile phones in a manner consistent with company values and legal compliance.\n",
      "Acceptable Use: Mobile devices are primarily intended for work-related tasks. Limited personal usage is allowed, provided it does not disrupt work obligations.\n",
      "Security: Safeguard your mobile device and access credentials. Exercise caution when downloading apps or clicking links from unfamiliar sources. Promptly report security concerns or suspicious activities related to your mobile device.\n",
      "Confidentiality: Avoid transmitting sensitive company information via unsecured messaging apps or emails. Be discreet when discussing company matters in public spaces.\n",
      "Cost Management: Keep personal phone usage separate from company accounts and reimburse the company for any personal charges on company-issued phones.\n",
      "Compliance: Adhere to all pertinent laws and regulations concerning mobile phone usage, including those related to data protection and privacy.\n",
      "Lost or Stolen Devices: Immediately report any lost or stolen mobile devices to the IT department or your supervisor.\n",
      "Consequences: Non-compliance with this policy may lead to disciplinary actions, including the potential loss of mobile phone privileges.\n",
      "The Mobile Phone Policy is aimed at promoting the responsible and secure use of mobile devices in line with legal and ethical standards. Every employee is expected to comprehend and abide by these guidelines. Regular reviews of the policy ensure its ongoing alignment with evolving technology and security best practices. 2.\tRecruitment Policy\n",
      "Answer: What is the Mobile Phone Recruitment Policy? The Mobile Phone Recruitment Policy sets forth the standards and expectations governing the appropriate and responsible use of mobile devices in the organization. The purpose of this policy is to ensure that employees utilize mobile phones in a manner consistent with company values and legal compliance.\n",
      "Acceptable Use: Mobile devices are primarily intended for work-related tasks. Limited personal usage is allowed, provided it does not disrupt work obligations.\n",
      "Security: Safeguard your mobile device and access credentials. Exercise caution when downloading apps or clicking links from unfamiliar sources. Promptly report security concerns\n",
      "================================================================================\n",
      "\n",
      "Settings: {'max_new_tokens': 100, 'min_length': 20, 'length_penalty': 2.5, 'num_beams': 6, 'temperature': 1.2}\n",
      "Generated Answer: Question: What is the mobile policy?\n",
      "Contexts: 4.\tMobile Phone Policy 9.\tDiscipline and Termination Policy 3.\tInternet and Email Policy The Mobile Phone Policy sets forth the standards and expectations governing the appropriate and responsible usage of mobile devices in the organization. The purpose of this policy is to ensure that employees utilize mobile phones in a manner consistent with company values and legal compliance.\n",
      "Acceptable Use: Mobile devices are primarily intended for work-related tasks. Limited personal usage is allowed, provided it does not disrupt work obligations.\n",
      "Security: Safeguard your mobile device and access credentials. Exercise caution when downloading apps or clicking links from unfamiliar sources. Promptly report security concerns or suspicious activities related to your mobile device.\n",
      "Confidentiality: Avoid transmitting sensitive company information via unsecured messaging apps or emails. Be discreet when discussing company matters in public spaces.\n",
      "Cost Management: Keep personal phone usage separate from company accounts and reimburse the company for any personal charges on company-issued phones.\n",
      "Compliance: Adhere to all pertinent laws and regulations concerning mobile phone usage, including those related to data protection and privacy.\n",
      "Lost or Stolen Devices: Immediately report any lost or stolen mobile devices to the IT department or your supervisor.\n",
      "Consequences: Non-compliance with this policy may lead to disciplinary actions, including the potential loss of mobile phone privileges.\n",
      "The Mobile Phone Policy is aimed at promoting the responsible and secure use of mobile devices in line with legal and ethical standards. Every employee is expected to comprehend and abide by these guidelines. Regular reviews of the policy ensure its ongoing alignment with evolving technology and security best practices. 2.\tRecruitment Policy\n",
      "Answer: What is the Mobile Phone Recruitment Policy? The Mobile Phone Recruitment Policy sets forth the standards and expectations governing the appropriate and responsible use of mobile devices in the organization. The purpose of this policy is to ensure that employees utilize mobile phones in a manner consistent with company values and legal compliance.\n",
      "Acceptable Use: Mobile devices are primarily intended for work-related tasks. Limited personal usage is allowed, provided it does not disrupt work obligations.\n",
      "Security: Safeguard your mobile device and\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# BEST PRACTICEs\n",
    "### Step 1: Project setup\n",
    "To begin, we need to install the required libraries. We’ll use:\n",
    "\n",
    "* **transformers** for the language model,\n",
    "* **sentence-transformers** for embedding generation,\n",
    "* **faiss-cpu** for efficient similarity search,\n",
    "* **torch** for tensor operations,\n",
    "* **wget** to download the file.\n",
    "* ``` pip install transformers sentence-transformers faiss-cpu torch wget ```"
   ],
   "id": "d1ecc95f89ca7841"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 2: Load and Preprocess Data",
   "id": "4ae5e0057435c68b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:38:38.010934Z",
     "start_time": "2025-03-31T13:38:36.791253Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 8,
   "source": [
    "import wget\n",
    "\n",
    "# Download the companyPolicies.txt file\n",
    "filename = 'companyPolicies.txt'\n",
    "url = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/6JDbUb_L3egv_eOkouY71A.txt'\n",
    "wget.download(url, out=filename)\n",
    "\n",
    "# Read and split the text into paragraphs\n",
    "with open(filename, 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "paragraphs = [para.strip() for para in text.split('\\n\\n') if len(para.strip()) > 10]"
   ],
   "id": "5972556b4a6cb805"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:40:30.772032Z",
     "start_time": "2025-03-31T13:40:26.388629Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install sentence-transformers",
   "id": "988a67d78e2b7a59",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-4.0.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\talib\\appdata\\roaming\\python\\python310\\site-packages (from sentence-transformers) (4.50.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from sentence-transformers) (0.29.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\talib\\appdata\\roaming\\python\\python310\\site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "Downloading sentence_transformers-4.0.1-py3-none-any.whl (340 kB)\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-4.0.1\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Step 3: Generate Embeddings\n",
    "For embeddings, we’ll use the **sentence-transformers** library, which provides state-of-the-art models optimized for semantic similarity. The all-MiniLM-L6-v2 model is lightweight, fast, and performs well for retrieval tasks.\n",
    "\n",
    "Explanation:\n",
    "\n",
    "all-MiniLM-L6-v2 is a high-quality, efficient model for generating dense embeddings.\n",
    "The embeddings are returned as a PyTorch tensor for compatibility with downstream operations."
   ],
   "id": "29578f4c217d8fd2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:41:31.053002Z",
     "start_time": "2025-03-31T13:41:09.526178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the embedding model\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Generate embeddings for the paragraphs\n",
    "embeddings = embedder.encode(paragraphs, convert_to_tensor=True)"
   ],
   "id": "6b63d1e38e7c4195",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Step 4: Create a FAISS Index\n",
    "FAISS (Facebook AI Similarity Search) enables fast similarity search over embeddings. We’ll use a simple IndexFlatL2 index, which computes L2 (Euclidean) distances between vectors."
   ],
   "id": "dfedb7a3f1001d48"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:42:01.806949Z",
     "start_time": "2025-03-31T13:42:01.786808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Convert embeddings to a numpy array (FAISS requires numpy)\n",
    "embeddings_np = embeddings.cpu().numpy()\n",
    "\n",
    "# Create a FAISS index\n",
    "dimension = embeddings_np.shape[1]  # Embedding dimension\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "# Add embeddings to the index\n",
    "index.add(embeddings_np)"
   ],
   "id": "8b8f44662bf8644c",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Step 5: Retrieve Relevant Contexts\n",
    "We’ll define a function to retrieve the top-k most relevant paragraphs for a given query based on embedding similarity.\n",
    "\n",
    "Explanation:\n",
    "\n",
    "* The query is embedded using the same model as the paragraphs.\n",
    "* index.search returns distances and indices of the top-k closest embeddings.\n",
    "* We map the indices back to the original paragraphs.\n"
   ],
   "id": "7ebb4a0a90dd9f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:43:02.459398Z",
     "start_time": "2025-03-31T13:43:02.436555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def retrieve_contexts(query, k=5):\n",
    "    # Generate embedding for the query\n",
    "    query_embedding = embedder.encode([query], convert_to_tensor=True).cpu().numpy()\n",
    "\n",
    "    # Search the FAISS index for the top-k closest paragraphs\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "    # Return the corresponding paragraphs\n",
    "    return [paragraphs[idx] for idx in indices[0]]"
   ],
   "id": "bdfa43e1c16f2120",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Step 6: Generate an Answer\n",
    "* For answer generation, we’ll use a question-answering model from Hugging Face’s transformers. The distilbert-base-uncased-distilled-squad model is a distilled version of BERT, fine-tuned on SQuAD, making it efficient and effective for this task.\n",
    "\n",
    "Explanation:\n",
    "\n",
    "* The pipeline simplifies loading and using the model.\n",
    "* Retrieved contexts are concatenated into one string, as the QA model expects a single context.\n",
    "* The model extracts the most relevant span from the context as the answer.\n"
   ],
   "id": "a2d492f253dab04f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:45:14.362247Z",
     "start_time": "2025-03-31T13:44:48.043464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the question-answering pipeline\n",
    "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
    "\n",
    "def generate_answer(query):\n",
    "    # Retrieve relevant contexts\n",
    "    contexts = retrieve_contexts(query, k=5)\n",
    "\n",
    "    # Combine contexts into a single string\n",
    "    context = \" \".join(contexts)\n",
    "\n",
    "    # Generate the answer using the QA pipeline\n",
    "    result = qa_pipeline(question=query, context=context)\n",
    "\n",
    "    return result['answer']"
   ],
   "id": "d140f5895e5c350",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 7: Test the System",
   "id": "f0bdb759bc79f12d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T13:45:36.401224Z",
     "start_time": "2025-03-31T13:45:34.668975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage\n",
    "query = \"What is the mobile policy?\"\n",
    "answer = generate_answer(query)\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Answer: {answer}\")"
   ],
   "id": "8d6357f0fcf042",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the mobile policy?\n",
      "Answer: responsible and secure use of mobile devices in line with legal and ethical standards\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Why This is Best Practice\n",
    "* Modularity: The code is broken into clear, reusable steps.\n",
    "* Efficiency: sentence-transformers and faiss provide fast, high-quality embeddings and retrieval.\n",
    "* Scalability: FAISS can be upgraded to more complex indices (e.g., IndexIVFFlat) for larger datasets.\n",
    "* State-of-the-Art Models: all-MiniLM-L6-v2 and distilbert-base-uncased-distilled-squad are modern, optimized models from Hugging Face.\n",
    "* Simplicity: The pipeline API abstracts away complexity, making the system easy to use and maintain."
   ],
   "id": "302e4d153968d96d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3d3499116b4795b4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
