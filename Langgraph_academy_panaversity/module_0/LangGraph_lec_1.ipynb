{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWGYu-pjkCsC"
   },
   "source": [
    "# We will see about langGraph\n",
    "- What langGraph is?\n",
    "- Why we use langGraph framework?\n",
    "- How we use langGraph?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B2fAZ9Y4kdz0"
   },
   "source": [
    "## What LangGraph is?\n",
    "LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows.\n",
    "\n",
    "### Key Features:\n",
    "\n",
    "- **Cycles and Branching:** Implement loops and conditionals in your apps.\n",
    "  - **Loops:** Imagine a chatbot that needs to ask the user a series of questions to gather information. LangGraph can create a loop that repeatedly asks questions until the user provides all the necessary data.\n",
    "  - **Conditionals:** If you're building a decision-making application, LangGraph can implement conditional statements to choose different paths based on specific criteria. For example, a customer support bot might offer different options based on the user's issue.\n",
    "\n",
    "- **Persistence:** Automatically save state after each step in the graph. Pause and resume the graph execution at any point to support error recovery, human-in-the-loop workflows, time travel and more.\n",
    "  - **State Saving:** LangGraph can automatically save the current state of your application after each step, ensuring that you can resume the workflow from where you left off if there's an interruption.\n",
    "  - **Pause and Resume:** If an error occurs or you need to review the workflow, you can pause the execution and resume it later. This feature is especially useful for human-in-the-loop workflows where a human needs to intervene.\n",
    "\n",
    "- **Human-in-the-Loop:** Interrupt graph execution to approve or edit next action planned by the agent.\n",
    "  - **Manual Intervention:** LangGraph allows you to pause the execution of the workflow and manually review or edit the next planned action. This is helpful for tasks that require human judgment or oversight.\n",
    "\n",
    "- **Streaming Support:** Stream outputs as they are produced by each node (including token streaming).\n",
    "  - **Real-time Outputs:** LangGraph can stream outputs as they are produced by each node, enabling real-time updates and progress tracking. This is particularly useful for applications that generate text or other data in a continuous stream.\n",
    "\n",
    "Integration with LangChain: LangGraph integrates seamlessly with LangChain and LangSmith (but does not require them)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOU8i_zXwwAL"
   },
   "source": [
    "## Example:\n",
    "**A Simple Chatbot**\n",
    "\n",
    "Imagine a chatbot that helps users find restaurants. It might follow this workflow:\n",
    "\n",
    "1. Greet the user: Welcome message.\n",
    "2. Ask for cuisine: Prompt the user to choose a cuisine.\n",
    "3. Ask for location: Prompt the user to specify a location.\n",
    "4. Search for restaurants: Use a tool to search for restaurants based on the user's preferences.\n",
    "5. Display results: Show the search results to the user.\n",
    "\n",
    "LangGraph could be used to create this workflow, with nodes representing each step and edges representing the transitions between them. Conditional edges could be used to handle different user responses, while persistence could be used to save the user's preferences for future interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUauTo8E7pi2"
   },
   "source": [
    "# Workflow Of Chatbot:\n",
    "![Chatbot Node Example](assests/example_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xf7zfjDbCB1C"
   },
   "source": [
    "# What is State, Node, Edges in LangGraph?\n",
    "- **State:** States define the different stages or points in the application's lifecycle. They can hold data, variables, or other information that influences the application's behavior.\n",
    "  - **State in Above Example:**\n",
    "    - **Start:** This is the initial state of the workflow, where the application begins execution.\n",
    "    - **End:** This is the final state of the workflow, indicating its completion.\n",
    "\n",
    "- **Node:** Nodes provide a clear structure and visualization of the workflow. They help in understanding the different steps or stages an application can go through.\n",
    "  - **Node in Above Example:**\n",
    "    - Chatbot: The central node representing the chatbot's interaction with the user.\n",
    "\n",
    "- **Edges:** Edges define the flow of execution in the application. They determine how the application moves from one state to another based on specific criteria or events. They can be unconditional (always leading to the next node) or conditional (leading to different nodes based on certain conditions).\n",
    "  - **Edges in Above Example:**\n",
    "    - **Start -> Chatbot:** The edge connecting the initial state to the chatbot node, indicating the workflow's progression.\n",
    "    - **Chatbot -> End:** The edge connecting the chatbot node to the final state, representing the completion of the interaction."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1klh-xiIIEe",
    "outputId": "aedb6426-91c8-4e35-a5e0-e782c3dde706",
    "ExecuteTime": {
     "end_time": "2025-02-18T16:16:42.562292Z",
     "start_time": "2025-02-18T16:16:34.192096Z"
    }
   },
   "source": [
    "!pip install -q -U langgraph"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u74b1sjmV9Xi",
    "outputId": "111889ef-7de2-419a-9268-0204b5d7a76b",
    "ExecuteTime": {
     "end_time": "2025-02-18T16:17:51.545727Z",
     "start_time": "2025-02-18T16:16:42.858133Z"
    }
   },
   "source": [
    "%pip install --quiet -U langchain_openai langchain_core langchain_community tavily-python\n",
    "%pip install python-dotenv"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CNQfogaxWCBp",
    "ExecuteTime": {
     "end_time": "2025-02-18T16:32:27.773290Z",
     "start_time": "2025-02-18T16:32:27.741736Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(r\"H:\\My_LangGraph_toturial\\.env\")\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = os.getenv(var)\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")\n"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oDkVDCMYWKaE",
    "ExecuteTime": {
     "end_time": "2025-02-18T16:32:40.823679Z",
     "start_time": "2025-02-18T16:32:40.319875Z"
    }
   },
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "gpt35_chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCCfA-1QIwN5"
   },
   "source": [
    "## State"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DIflxxj4H2LK",
    "ExecuteTime": {
     "end_time": "2025-02-18T16:32:45.456760Z",
     "start_time": "2025-02-18T16:32:45.445812Z"
    }
   },
   "source": [
    "# How we define a state in code:\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    graph_state: str"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2U_kERLfrz9"
   },
   "source": [
    "## Construct Graph"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7LaoOPRtTfsu",
    "outputId": "d7aab428-e6d6-4087-e72e-ef6a9b9eac6d",
    "ExecuteTime": {
     "end_time": "2025-02-18T16:32:47.604675Z",
     "start_time": "2025-02-18T16:32:47.590056Z"
    }
   },
   "source": [
    "# For defining nodes and edges we need graph, so construct the graph first\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x144824e5990>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RdGQ4v7yfzgD"
   },
   "source": [
    "## Node"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ytuo7ms9K_mQ",
    "outputId": "8bfa8829-06f7-41e2-ee4d-18ab5d59d5bd",
    "ExecuteTime": {
     "end_time": "2025-02-18T16:32:49.145823Z",
     "start_time": "2025-02-18T16:32:49.130669Z"
    }
   },
   "source": [
    "# We will add node\n",
    "def chatbot(state: MessagesState): #whenever we create any node in this graph builder, we have to pass MessageState in it because based on state message, the state management will keep on changing\n",
    "  return {\"graph_state\": gpt35_chat.invoke(state[\"graph_state\"])}\n",
    "\n",
    "builder.add_node(\"chatbot\", chatbot)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x144824e5990>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43F002Elf1T-"
   },
   "source": [
    "## Edge"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hYPWQ9DmSZj8",
    "outputId": "6f0cc24c-2197-424f-b166-48d1e5eb4ea2",
    "ExecuteTime": {
     "end_time": "2025-02-18T16:32:50.747592Z",
     "start_time": "2025-02-18T16:32:50.732311Z"
    }
   },
   "source": [
    "# we will add edges like this\n",
    "from langgraph.graph import START, END\n",
    "\n",
    "builder.add_edge(START, \"chatbot\")\n",
    "builder.add_edge(\"chatbot\", END)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x144824e5990>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJ5tR_J1f4V2"
   },
   "source": [
    "## Compile the Graph"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3K20dcJrVjzO",
    "ExecuteTime": {
     "end_time": "2025-02-18T16:32:52.906263Z",
     "start_time": "2025-02-18T16:32:52.893259Z"
    }
   },
   "source": [
    "# compile a graph to view it\n",
    "graph = builder.compile()"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3EkbicGbf8KR"
   },
   "source": [
    "## View Graph"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "id": "Gyx07xbcVndh",
    "outputId": "8b445516-f8e6-476d-d301-d0a54a35de5b",
    "ExecuteTime": {
     "end_time": "2025-02-18T16:32:54.533878Z",
     "start_time": "2025-02-18T16:32:54.477213Z"
    }
   },
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ],
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKQANQ8Hf-28"
   },
   "source": [
    "## Test Application"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "U4Muf9k0Xn2Z",
    "outputId": "5c038413-f4e2-4ac2-9cb1-06e184a5f040",
    "ExecuteTime": {
     "end_time": "2025-02-18T16:32:56.850811Z",
     "start_time": "2025-02-18T16:32:56.463261Z"
    }
   },
   "source": [
    "# test our agent\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "result = graph.invoke({\"graph_state\": [HumanMessage(content=\"Hi, this is Math Class. What is 10x2?\")]})\n",
    "result['graph_state'].content"
   ],
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-12345***********************cdef. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAuthenticationError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[40], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# test our agent\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_core\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmessages\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AIMessage, HumanMessage\n\u001B[1;32m----> 3\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mgraph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgraph_state\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mHumanMessage\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcontent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mHi, this is Math Class. What is 10x2?\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m result[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgraph_state\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mcontent\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\panaversity\\lib\\site-packages\\langgraph\\pregel\\__init__.py:2142\u001B[0m, in \u001B[0;36mPregel.invoke\u001B[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001B[0m\n\u001B[0;32m   2140\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2141\u001B[0m     chunks \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m-> 2142\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream(\n\u001B[0;32m   2143\u001B[0m     \u001B[38;5;28minput\u001B[39m,\n\u001B[0;32m   2144\u001B[0m     config,\n\u001B[0;32m   2145\u001B[0m     stream_mode\u001B[38;5;241m=\u001B[39mstream_mode,\n\u001B[0;32m   2146\u001B[0m     output_keys\u001B[38;5;241m=\u001B[39moutput_keys,\n\u001B[0;32m   2147\u001B[0m     interrupt_before\u001B[38;5;241m=\u001B[39minterrupt_before,\n\u001B[0;32m   2148\u001B[0m     interrupt_after\u001B[38;5;241m=\u001B[39minterrupt_after,\n\u001B[0;32m   2149\u001B[0m     debug\u001B[38;5;241m=\u001B[39mdebug,\n\u001B[0;32m   2150\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   2151\u001B[0m ):\n\u001B[0;32m   2152\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m stream_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalues\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   2153\u001B[0m         latest \u001B[38;5;241m=\u001B[39m chunk\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\panaversity\\lib\\site-packages\\langgraph\\pregel\\__init__.py:1797\u001B[0m, in \u001B[0;36mPregel.stream\u001B[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001B[0m\n\u001B[0;32m   1791\u001B[0m     \u001B[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001B[39;00m\n\u001B[0;32m   1792\u001B[0m     \u001B[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001B[39;00m\n\u001B[0;32m   1793\u001B[0m     \u001B[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001B[39;00m\n\u001B[0;32m   1794\u001B[0m     \u001B[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001B[39;00m\n\u001B[0;32m   1795\u001B[0m     \u001B[38;5;66;03m# with channel updates applied only at the transition between steps.\u001B[39;00m\n\u001B[0;32m   1796\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m loop\u001B[38;5;241m.\u001B[39mtick(input_keys\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_channels):\n\u001B[1;32m-> 1797\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m runner\u001B[38;5;241m.\u001B[39mtick(\n\u001B[0;32m   1798\u001B[0m             loop\u001B[38;5;241m.\u001B[39mtasks\u001B[38;5;241m.\u001B[39mvalues(),\n\u001B[0;32m   1799\u001B[0m             timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstep_timeout,\n\u001B[0;32m   1800\u001B[0m             retry_policy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mretry_policy,\n\u001B[0;32m   1801\u001B[0m             get_waiter\u001B[38;5;241m=\u001B[39mget_waiter,\n\u001B[0;32m   1802\u001B[0m         ):\n\u001B[0;32m   1803\u001B[0m             \u001B[38;5;66;03m# emit output\u001B[39;00m\n\u001B[0;32m   1804\u001B[0m             \u001B[38;5;28;01myield from\u001B[39;00m output()\n\u001B[0;32m   1805\u001B[0m \u001B[38;5;66;03m# emit output\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\panaversity\\lib\\site-packages\\langgraph\\pregel\\runner.py:230\u001B[0m, in \u001B[0;36mPregelRunner.tick\u001B[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001B[0m\n\u001B[0;32m    228\u001B[0m t \u001B[38;5;241m=\u001B[39m tasks[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    229\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 230\u001B[0m     \u001B[43mrun_with_retry\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    231\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    232\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretry_policy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    233\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfigurable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\n\u001B[0;32m    234\u001B[0m \u001B[43m            \u001B[49m\u001B[43mCONFIG_KEY_SEND\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpartial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwriter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    235\u001B[0m \u001B[43m            \u001B[49m\u001B[43mCONFIG_KEY_CALL\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpartial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcall\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    236\u001B[0m \u001B[43m        \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    237\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    238\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommit(t, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    239\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\panaversity\\lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001B[0m, in \u001B[0;36mrun_with_retry\u001B[1;34m(task, retry_policy, configurable)\u001B[0m\n\u001B[0;32m     38\u001B[0m     task\u001B[38;5;241m.\u001B[39mwrites\u001B[38;5;241m.\u001B[39mclear()\n\u001B[0;32m     39\u001B[0m     \u001B[38;5;66;03m# run the task\u001B[39;00m\n\u001B[1;32m---> 40\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtask\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mproc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtask\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ParentCommand \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[0;32m     42\u001B[0m     ns: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\panaversity\\lib\\site-packages\\langgraph\\utils\\runnable.py:546\u001B[0m, in \u001B[0;36mRunnableSeq.invoke\u001B[1;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[0;32m    542\u001B[0m config \u001B[38;5;241m=\u001B[39m patch_config(\n\u001B[0;32m    543\u001B[0m     config, callbacks\u001B[38;5;241m=\u001B[39mrun_manager\u001B[38;5;241m.\u001B[39mget_child(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mseq:step:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    544\u001B[0m )\n\u001B[0;32m    545\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 546\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m step\u001B[38;5;241m.\u001B[39minvoke(\u001B[38;5;28minput\u001B[39m, config, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    547\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    548\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m step\u001B[38;5;241m.\u001B[39minvoke(\u001B[38;5;28minput\u001B[39m, config)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\panaversity\\lib\\site-packages\\langgraph\\utils\\runnable.py:310\u001B[0m, in \u001B[0;36mRunnableCallable.invoke\u001B[1;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[0;32m    308\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    309\u001B[0m     context\u001B[38;5;241m.\u001B[39mrun(_set_config_context, config)\n\u001B[1;32m--> 310\u001B[0m     ret \u001B[38;5;241m=\u001B[39m context\u001B[38;5;241m.\u001B[39mrun(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunc, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    311\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(ret, Runnable) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrecurse:\n\u001B[0;32m    312\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ret\u001B[38;5;241m.\u001B[39minvoke(\u001B[38;5;28minput\u001B[39m, config)\n",
      "Cell \u001B[1;32mIn[36], line 3\u001B[0m, in \u001B[0;36mchatbot\u001B[1;34m(state)\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mchatbot\u001B[39m(state: MessagesState): \u001B[38;5;66;03m#whenever we create any node in this graph builder, we have to pass MessageState in it because based on state message, the state management will keep on changing\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgraph_state\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[43mgpt35_chat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgraph_state\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m}\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\panaversity\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:284\u001B[0m, in \u001B[0;36mBaseChatModel.invoke\u001B[1;34m(self, input, config, stop, **kwargs)\u001B[0m\n\u001B[0;32m    273\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minvoke\u001B[39m(\n\u001B[0;32m    274\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    275\u001B[0m     \u001B[38;5;28minput\u001B[39m: LanguageModelInput,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    279\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m    280\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m BaseMessage:\n\u001B[0;32m    281\u001B[0m     config \u001B[38;5;241m=\u001B[39m ensure_config(config)\n\u001B[0;32m    282\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(\n\u001B[0;32m    283\u001B[0m         ChatGeneration,\n\u001B[1;32m--> 284\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgenerate_prompt(\n\u001B[0;32m    285\u001B[0m             [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_convert_input(\u001B[38;5;28minput\u001B[39m)],\n\u001B[0;32m    286\u001B[0m             stop\u001B[38;5;241m=\u001B[39mstop,\n\u001B[0;32m    287\u001B[0m             callbacks\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcallbacks\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m    288\u001B[0m             tags\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtags\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m    289\u001B[0m             metadata\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m    290\u001B[0m             run_name\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_name\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m    291\u001B[0m             run_id\u001B[38;5;241m=\u001B[39mconfig\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_id\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[0;32m    292\u001B[0m             \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    293\u001B[0m         )\u001B[38;5;241m.\u001B[39mgenerations[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m    294\u001B[0m     )\u001B[38;5;241m.\u001B[39mmessage\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\panaversity\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:860\u001B[0m, in \u001B[0;36mBaseChatModel.generate_prompt\u001B[1;34m(self, prompts, stop, callbacks, **kwargs)\u001B[0m\n\u001B[0;32m    852\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate_prompt\u001B[39m(\n\u001B[0;32m    853\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    854\u001B[0m     prompts: \u001B[38;5;28mlist\u001B[39m[PromptValue],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    857\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m    858\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m LLMResult:\n\u001B[0;32m    859\u001B[0m     prompt_messages \u001B[38;5;241m=\u001B[39m [p\u001B[38;5;241m.\u001B[39mto_messages() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[1;32m--> 860\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgenerate(prompt_messages, stop\u001B[38;5;241m=\u001B[39mstop, callbacks\u001B[38;5;241m=\u001B[39mcallbacks, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\panaversity\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:690\u001B[0m, in \u001B[0;36mBaseChatModel.generate\u001B[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[0m\n\u001B[0;32m    687\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(messages):\n\u001B[0;32m    688\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    689\u001B[0m         results\u001B[38;5;241m.\u001B[39mappend(\n\u001B[1;32m--> 690\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate_with_cache(\n\u001B[0;32m    691\u001B[0m                 m,\n\u001B[0;32m    692\u001B[0m                 stop\u001B[38;5;241m=\u001B[39mstop,\n\u001B[0;32m    693\u001B[0m                 run_manager\u001B[38;5;241m=\u001B[39mrun_managers[i] \u001B[38;5;28;01mif\u001B[39;00m run_managers \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    694\u001B[0m                 \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    695\u001B[0m             )\n\u001B[0;32m    696\u001B[0m         )\n\u001B[0;32m    697\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    698\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\panaversity\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:925\u001B[0m, in \u001B[0;36mBaseChatModel._generate_with_cache\u001B[1;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[0;32m    923\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    924\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m inspect\u001B[38;5;241m.\u001B[39msignature(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate)\u001B[38;5;241m.\u001B[39mparameters\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_manager\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 925\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate(\n\u001B[0;32m    926\u001B[0m             messages, stop\u001B[38;5;241m=\u001B[39mstop, run_manager\u001B[38;5;241m=\u001B[39mrun_manager, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    927\u001B[0m         )\n\u001B[0;32m    928\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    929\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate(messages, stop\u001B[38;5;241m=\u001B[39mstop, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\panaversity\\lib\\site-packages\\langchain_openai\\chat_models\\base.py:783\u001B[0m, in \u001B[0;36mBaseChatOpenAI._generate\u001B[1;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[0;32m    781\u001B[0m     generation_info \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mheaders\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mdict\u001B[39m(raw_response\u001B[38;5;241m.\u001B[39mheaders)}\n\u001B[0;32m    782\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 783\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclient\u001B[38;5;241m.\u001B[39mcreate(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpayload)\n\u001B[0;32m    784\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_create_chat_result(response, generation_info)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\panaversity\\lib\\site-packages\\openai\\_utils\\_utils.py:279\u001B[0m, in \u001B[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    277\u001B[0m             msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMissing required argument: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquote(missing[\u001B[38;5;241m0\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    278\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[1;32m--> 279\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\panaversity\\lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:879\u001B[0m, in \u001B[0;36mCompletions.create\u001B[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[0;32m    837\u001B[0m \u001B[38;5;129m@required_args\u001B[39m([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m], [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m    838\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate\u001B[39m(\n\u001B[0;32m    839\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    876\u001B[0m     timeout: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m|\u001B[39m httpx\u001B[38;5;241m.\u001B[39mTimeout \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m|\u001B[39m NotGiven \u001B[38;5;241m=\u001B[39m NOT_GIVEN,\n\u001B[0;32m    877\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ChatCompletion \u001B[38;5;241m|\u001B[39m Stream[ChatCompletionChunk]:\n\u001B[0;32m    878\u001B[0m     validate_response_format(response_format)\n\u001B[1;32m--> 879\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    880\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/chat/completions\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    881\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    882\u001B[0m \u001B[43m            \u001B[49m\u001B[43m{\u001B[49m\n\u001B[0;32m    883\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmessages\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    884\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    885\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43maudio\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43maudio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    886\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfrequency_penalty\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrequency_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    887\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfunction_call\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunction_call\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    888\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfunctions\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunctions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    889\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlogit_bias\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogit_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    890\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlogprobs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    891\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmax_completion_tokens\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_completion_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    892\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmax_tokens\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    893\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmetadata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    894\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodalities\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodalities\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    895\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mn\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    896\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mparallel_tool_calls\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mparallel_tool_calls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    897\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprediction\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprediction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    898\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpresence_penalty\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpresence_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    899\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mreasoning_effort\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mreasoning_effort\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    900\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mresponse_format\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    901\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mseed\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    902\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mservice_tier\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mservice_tier\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    903\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstop\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    904\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstore\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstore\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    905\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstream\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    906\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstream_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    907\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtemperature\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    908\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtool_choice\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtool_choice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    909\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtools\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    910\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtop_logprobs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_logprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    911\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtop_p\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    912\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43muser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    913\u001B[0m \u001B[43m            \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    914\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcompletion_create_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCompletionCreateParams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    915\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    916\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    917\u001B[0m \u001B[43m            \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\n\u001B[0;32m    918\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    919\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mChatCompletion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    920\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    921\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mStream\u001B[49m\u001B[43m[\u001B[49m\u001B[43mChatCompletionChunk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    922\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\panaversity\\lib\\site-packages\\openai\\_base_client.py:1290\u001B[0m, in \u001B[0;36mSyncAPIClient.post\u001B[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[0;32m   1276\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost\u001B[39m(\n\u001B[0;32m   1277\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   1278\u001B[0m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1285\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1286\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[0;32m   1287\u001B[0m     opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(\n\u001B[0;32m   1288\u001B[0m         method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, files\u001B[38;5;241m=\u001B[39mto_httpx_files(files), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions\n\u001B[0;32m   1289\u001B[0m     )\n\u001B[1;32m-> 1290\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\panaversity\\lib\\site-packages\\openai\\_base_client.py:967\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[0;32m    964\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    965\u001B[0m     retries_taken \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m--> 967\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    968\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    969\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    970\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    971\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    972\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretries_taken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretries_taken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    973\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\panaversity\\lib\\site-packages\\openai\\_base_client.py:1071\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001B[0m\n\u001B[0;32m   1068\u001B[0m         err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mread()\n\u001B[0;32m   1070\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRe-raising status error\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1071\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_status_error_from_response(err\u001B[38;5;241m.\u001B[39mresponse) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1073\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_response(\n\u001B[0;32m   1074\u001B[0m     cast_to\u001B[38;5;241m=\u001B[39mcast_to,\n\u001B[0;32m   1075\u001B[0m     options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1079\u001B[0m     retries_taken\u001B[38;5;241m=\u001B[39mretries_taken,\n\u001B[0;32m   1080\u001B[0m )\n",
      "\u001B[1;31mAuthenticationError\u001B[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-12345***********************cdef. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "id": "Zt3viYwgfUc9",
    "outputId": "bb0405d4-3a8d-4f9d-fa50-a6871db06b57"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Quantum physics! It\\'s a fascinating and mind-bending subject that has revolutionized our understanding of the universe. Here\\'s a brief introduction to the basics:\\n\\n**What is quantum physics?**\\n\\nQuantum physics, also known as quantum mechanics, is a branch of physics that studies the behavior of matter and energy at an atomic and subatomic level. It\\'s a way to understand the tiny world where classical physics no longer applies.\\n\\n**Key principles:**\\n\\n1. **Wave-particle duality**: Quantum objects, like electrons, can exhibit both wave-like and particle-like behavior depending on how they\\'re observed.\\n2. **Uncertainty principle**: It\\'s impossible to know certain properties of a quantum object, like position and momentum, simultaneously with infinite precision.\\n3. **Superposition**: Quantum objects can exist in multiple states simultaneously, which is known as a superposition of states.\\n4. **Entanglement**: Quantum objects can become \"entangled\" in a way that their properties are connected, even when separated by large distances.\\n5. **Quantization**: Quantum mechanics introduces a fundamental discreteness in the physical world, where certain quantities, like energy, can only take on specific discrete values.\\n\\n**Quantum weirdness:**\\n\\n1. **Schrdinger\\'s cat**: A thought experiment where a cat is in a superposition of states, both alive and dead, until observed.\\n2. **Quantum spin**: Quantum objects can have an intrinsic angular momentum, known as spin, which is neither purely classical nor purely wave-like.\\n3. **Quantum tunneling**: Quantum objects can pass through barriers or gaps that would be classically impossible to traverse.\\n\\n**Applications:**\\n\\n1. **Transistors**: The building blocks of modern electronics rely on quantum mechanics to control the flow of electric current.\\n2. **Lasers**: Quantum mechanics is essential for understanding the behavior of light and its interaction with matter.\\n3. **Computer chips**: Quantum computing and cryptography rely on the principles of quantum mechanics.\\n4. **Medical imaging**: Quantum mechanics is used in MRI and PET scans to visualize the human body.\\n\\n**Challenges and open questions:**\\n\\n1. **Interpretation of quantum mechanics**: There\\'s ongoing debate about the meaning and implications of quantum mechanics, particularly the role of observation and measurement.\\n2. **Quantum gravity**: The integration of quantum mechanics and general relativity, the theory of gravity, is an open problem in physics.\\n3. **Quantum error correction**: Developing practical methods to correct errors in quantum computations and communications.\\n\\nThis is just a brief glimpse into the fascinating world of quantum physics. If you\\'re interested in learning more, I\\'d be happy to provide additional resources and insights!'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test our agent\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "result = graph.invoke({\"graph_state\": [HumanMessage(content=\"Hi, tell me basics about quantum physics?\")]})\n",
    "result['graph_state'].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYmuZjtxHQ58"
   },
   "source": [
    "## Conditional Edges:\n",
    "Now we know that edges can be conditional and unconditional we have already seen unconditional edge. Now check the Conditional Edge example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gl1lvoCcH9Qg"
   },
   "source": [
    "# The Simplest Graph\n",
    "\n",
    "Let's build a simple graph with 3 nodes and one conditional edge.\n",
    "\n",
    "![Screenshot 2024-08-20 at 3.11.22 PM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dba5f465f6e9a2482ad935_simple-graph1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "E_tq6l41_M7K"
   },
   "outputs": [],
   "source": [
    "%pip install --quiet -U langgraph # we already install it above so no need here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zqnTMVUgkW3"
   },
   "source": [
    "## State\n",
    "\n",
    "First, define the [State](https://langchain-ai.github.io/langgraph/concepts/low_level/#state) of the graph.\n",
    "\n",
    "The State schema serves as the input schema for all Nodes and Edges in the graph.\n",
    "\n",
    "Let's use the `TypedDict` class from python's `typing` module as our schema, which provides type hints for the keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "R3yYqg3Cgg90"
   },
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    graph_state: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Zuzc_fsgop0"
   },
   "source": [
    "## Nodes\n",
    "\n",
    "[Nodes](https://langchain-ai.github.io/langgraph/concepts/low_level/#nodes) are just python functions.\n",
    "\n",
    "The first positional argument is the state, as defined above.\n",
    "\n",
    "Because the state is a `TypedDict` with schema as defined above, each node can access the key, `graph_state`, with `state['graph_state']`.\n",
    "\n",
    "Each node returns a new value of the state key `graph_state`.\n",
    "  \n",
    "By default, the new value returned by each node [will override](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers) the prior state value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "ZNEUcNwXgm5G"
   },
   "outputs": [],
   "source": [
    "def node_1(state):\n",
    "    print(\"---Node 1---\")\n",
    "    return {\"graph_state\": state['graph_state'] +\" I am\"}\n",
    "\n",
    "def node_2(state):\n",
    "    print(\"---Node 2---\")\n",
    "    return {\"graph_state\": state['graph_state'] +\" happy!\"}\n",
    "\n",
    "def node_3(state):\n",
    "    print(\"---Node 3---\")\n",
    "    return {\"graph_state\": state['graph_state'] +\" sad!\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yE851LujhDod"
   },
   "source": [
    "## Edges\n",
    "\n",
    "[Edges](https://langchain-ai.github.io/langgraph/concepts/low_level/#edges) connect the nodes.\n",
    "\n",
    "Normal Edges are used if you want to *always* go from, for example, `node_1` to `node_2`.\n",
    "\n",
    "[Conditional Edges](https://langchain-ai.github.io/langgraph/reference/graphs/?h=conditional+edge#langgraph.graph.StateGraph.add_conditional_edges) are used want to *optionally* route between nodes.\n",
    "\n",
    "Conditional edges are implemented as functions that return the next node to visit based upon some logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "aNjkp1b0gyKh"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Literal\n",
    "\n",
    "def decide_mood(state) -> Literal[\"node_2\", \"node_3\"]:\n",
    "\n",
    "    # Often, we will use state to decide on the next node to visit\n",
    "    user_input = state['graph_state']\n",
    "\n",
    "    # Here, let's just do a 50 / 50 split between nodes 2, 3\n",
    "    if random.random() < 0.5:\n",
    "\n",
    "        # 50% of the time, we return Node 2\n",
    "        return \"node_2\"\n",
    "\n",
    "    # 50% of the time, we return Node 3\n",
    "    return \"node_3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yv393l7LimsS"
   },
   "source": [
    "## Graph Construction\n",
    "\n",
    "Now, we build the graph from our [components](\n",
    "https://langchain-ai.github.io/langgraph/concepts/low_level/) defined above.\n",
    "\n",
    "The [StateGraph class](https://langchain-ai.github.io/langgraph/concepts/low_level/#stategraph) is the graph class that we can use.\n",
    "\n",
    "First, we initialize a StateGraph with the `State` class we defined above.\n",
    "\n",
    "Then, we add our nodes and edges.\n",
    "\n",
    "We use the [`START` Node, a special node](https://langchain-ai.github.io/langgraph/concepts/low_level/#start-node) that sends user input to the graph, to indicate where to start our graph.\n",
    "\n",
    "The [`END` Node](https://langchain-ai.github.io/langgraph/concepts/low_level/#end-node) is a special node that represents a terminal node.\n",
    "\n",
    "Finally, we [compile our graph](https://langchain-ai.github.io/langgraph/concepts/low_level/#compiling-your-graph) to perform a few basic checks on the graph structure.\n",
    "\n",
    "We can visualize the graph as a [Mermaid diagram](https://github.com/mermaid-js/mermaid)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "kgY9IfluherI",
    "outputId": "e379a1ea-4fb1-4bb1-a268-ccab750d3c93"
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "builder.add_node(\"node_2\", node_2)\n",
    "builder.add_node(\"node_3\", node_3)\n",
    "\n",
    "# Logic\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_conditional_edges(\"node_1\", decide_mood)\n",
    "builder.add_edge(\"node_2\", END)\n",
    "builder.add_edge(\"node_3\", END)\n",
    "\n",
    "# Add\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "irCuyOLsjDa9"
   },
   "source": [
    "## Graph Invocation\n",
    "\n",
    "The compiled graph implements the [runnable](https://python.langchain.com/v0.1/docs/expression_language/interface/) protocol.\n",
    "\n",
    "This provides a standard way to execute LangChain components.\n",
    "\n",
    "`invoke` is one of the standard methods in this interface.\n",
    "\n",
    "The input is a dictionary `{\"graph_state\": \"Hi, this is lance.\"}`, which sets the initial value for our graph state dict.\n",
    "\n",
    "When `invoke` is called, the graph starts execution from the `START` node.\n",
    "\n",
    "It progresses through the defined nodes (`node_1`, `node_2`, `node_3`) in order.\n",
    "\n",
    "The conditional edge will traverse from node `1` to node `2` or `3` using a 50/50 decision rule.\n",
    "\n",
    "Each node function receives the current state and returns a new value, which overrides the graph state.\n",
    "\n",
    "The execution continues until it reaches the `END` node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qr8JU_Vaipnd",
    "outputId": "de707718-530b-4c77-e4f2-13fb0b352897"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Node 1---\n",
      "---Node 3---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'graph_state': 'Hi, this is Lance. I am sad!'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"graph_state\" : \"Hi, this is Lance.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKm_PQuljTPY"
   },
   "source": [
    "`invoke` runs the entire graph synchronously.\n",
    "\n",
    "This waits for each step to complete before moving to the next.\n",
    "\n",
    "It returns the final state of the graph after all nodes have executed.\n",
    "\n",
    "In this case, it returns the state after `node_3` has completed:\n",
    "\n",
    "```\n",
    "{'graph_state': 'Hi, this is Lance. I am sad!'}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
