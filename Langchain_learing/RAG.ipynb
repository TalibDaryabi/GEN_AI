{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T21:04:02.817848Z",
     "start_time": "2025-03-07T21:04:02.791249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(r\"H:\\My_LangGraph_toturial\\.env\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"ACTIVELOOP_TOKEN\"] = os.getenv(\"ACTIVELOOP_TOKEN\")"
   ],
   "id": "95d327866ce9fc9f",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-07T21:04:26.589822Z",
     "start_time": "2025-03-07T21:04:22.592820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.9)\n",
    "prompt = ChatPromptTemplate.from_template(\"What is a good name for a company that makes {product}?\")\n",
    "\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "print(chain.invoke({\"product\": \"eco-friendly water bottles\"}))\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GreenHydro EcoBottles\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T09:43:10.435244Z",
     "start_time": "2025-03-08T09:43:06.803980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import uuid\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "# Define a chat model\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    response = model.invoke(state[\"messages\"])\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [AIMessage(content=response.content)]}\n",
    "\n",
    "# Define the nodes we will cycle between\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "# Adding memory\n",
    "memory = MemorySaver()\n",
    "\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "# Generate a unique thread ID for this conversation\n",
    "thread_id = uuid.uuid4()\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "# Function to process messages and print responses\n",
    "def process_message(content):\n",
    "    input_message = HumanMessage(content=content)\n",
    "    for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "        event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "# Start the conversation\n",
    "print(\"AI: Tell me about yourself.\")\n",
    "process_message(\"Tell me about yourself.\")\n",
    "\n",
    "print(\"\\nAI: What can you do?\")\n",
    "process_message(\"What can you do?\")\n",
    "\n",
    "print(\"\\nAI: How can you help me with data analysis?\")\n",
    "process_message(\"How can you help me with data analysis?\")\n",
    "\n",
    "# Display the full conversation history\n",
    "print(\"\\nFull Conversation History:\")\n",
    "for message in app.checkpointer.get(thread_id)[\"messages\"]:\n",
    "    if isinstance(message, SystemMessage):\n",
    "        print(f\"System: {message.content}\")\n",
    "    elif isinstance(message, HumanMessage):\n",
    "        print(f\"Human: {message.content}\")\n",
    "    elif isinstance(message, AIMessage):\n",
    "        print(f\"AI: {message.content}\")\n"
   ],
   "id": "c298ac0fd15b7cc4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Tell me about yourself.\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Tell me about yourself.\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "I am a language model AI created by OpenAI. I am designed to assist with a wide range of tasks, including answering questions, providing information, and engaging in conversation. I am constantly learning and improving my abilities to better assist users like you. How can I help you today?\n",
      "\n",
      "AI: What can you do?\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "What can you do?\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "I can help with a variety of tasks, such as answering questions, providing information on a wide range of topics, assisting with writing and editing text, generating ideas or suggestions, and engaging in conversation. I can also provide recommendations, offer guidance, and assist with problem-solving. Feel free to ask me anything, and I will do my best to help you!\n",
      "\n",
      "AI: How can you help me with data analysis?\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "How can you help me with data analysis?\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "I can assist with data analysis by helping you understand and interpret your data, providing guidance on statistical methods and techniques, and offering suggestions on how to visualize and present your data effectively. I can also help you with data cleaning, data manipulation, and data visualization using various tools and programming languages. Additionally, I can generate insights and recommendations based on the analysis of your data. If you have specific questions or need assistance with a particular data analysis task, feel free to ask, and I will do my best to help you.\n",
      "\n",
      "Full Conversation History:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'UUID' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 50\u001B[0m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;66;03m# Display the full conversation history\u001B[39;00m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mFull Conversation History:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 50\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m message \u001B[38;5;129;01min\u001B[39;00m \u001B[43mapp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcheckpointer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread_id\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(message, SystemMessage):\n\u001B[0;32m     52\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSystem: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmessage\u001B[38;5;241m.\u001B[39mcontent\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\panaversity\\lib\\site-packages\\langgraph\\checkpoint\\base\\__init__.py:236\u001B[0m, in \u001B[0;36mBaseCheckpointSaver.get\u001B[1;34m(self, config)\u001B[0m\n\u001B[0;32m    227\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(\u001B[38;5;28mself\u001B[39m, config: RunnableConfig) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Optional[Checkpoint]:\n\u001B[0;32m    228\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Fetch a checkpoint using the given configuration.\u001B[39;00m\n\u001B[0;32m    229\u001B[0m \n\u001B[0;32m    230\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    234\u001B[0m \u001B[38;5;124;03m        Optional[Checkpoint]: The requested checkpoint, or None if not found.\u001B[39;00m\n\u001B[0;32m    235\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 236\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m value \u001B[38;5;241m:=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_tuple\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m    237\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m value\u001B[38;5;241m.\u001B[39mcheckpoint\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\panaversity\\lib\\site-packages\\langgraph\\checkpoint\\memory\\__init__.py:124\u001B[0m, in \u001B[0;36mInMemorySaver.get_tuple\u001B[1;34m(self, config)\u001B[0m\n\u001B[0;32m    110\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_tuple\u001B[39m(\u001B[38;5;28mself\u001B[39m, config: RunnableConfig) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Optional[CheckpointTuple]:\n\u001B[0;32m    111\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Get a checkpoint tuple from the in-memory storage.\u001B[39;00m\n\u001B[0;32m    112\u001B[0m \n\u001B[0;32m    113\u001B[0m \u001B[38;5;124;03m    This method retrieves a checkpoint tuple from the in-memory storage based on the\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    122\u001B[0m \u001B[38;5;124;03m        Optional[CheckpointTuple]: The retrieved checkpoint tuple, or None if no matching checkpoint was found.\u001B[39;00m\n\u001B[0;32m    123\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 124\u001B[0m     thread_id \u001B[38;5;241m=\u001B[39m \u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mconfigurable\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthread_id\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    125\u001B[0m     checkpoint_ns \u001B[38;5;241m=\u001B[39m config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconfigurable\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcheckpoint_ns\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    126\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m checkpoint_id \u001B[38;5;241m:=\u001B[39m get_checkpoint_id(config):\n",
      "\u001B[1;31mTypeError\u001B[0m: 'UUID' object is not subscriptable"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T09:45:03.173732Z",
     "start_time": "2025-03-08T09:45:03.132973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "checkpoint_tuple = app.checkpointer.get_tuple(thread_id=str(thread_id))\n",
    "messages = checkpoint_tuple.state[\"messages\"]\n",
    "message"
   ],
   "id": "8d71befe2bb64990",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "InMemorySaver.get_tuple() got an unexpected keyword argument 'thread_id'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m checkpoint_tuple \u001B[38;5;241m=\u001B[39m \u001B[43mapp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcheckpointer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_tuple\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mthread_id\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m messages \u001B[38;5;241m=\u001B[39m checkpoint_tuple\u001B[38;5;241m.\u001B[39mstate[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m      3\u001B[0m message\n",
      "\u001B[1;31mTypeError\u001B[0m: InMemorySaver.get_tuple() got an unexpected keyword argument 'thread_id'"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e5e24d0ef9bedd6d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
