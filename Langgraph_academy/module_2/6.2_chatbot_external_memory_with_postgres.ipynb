{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Chatbot with message summarization & external DB memory\n",
    "\n",
    "## Review\n",
    "\n",
    "We've covered how to customize graph state schema and reducer.\n",
    "\n",
    "We've also shown a number of tricks for trimming or filtering messages in graph state.\n",
    "\n",
    "We've used these concepts in a Chatbot with memory that produces a running summary of the conversation.\n",
    "\n",
    "## Goals\n",
    "\n",
    "But, what if we want our Chatbot to have memory that persists indefinitely?\n",
    "\n",
    "Now, we'll introduce some more advanced checkpointers that support external databases.\n",
    "\n",
    "Here, we'll show how to use [Postgres as a checkpointer](https://langchain-ai.github.io/langgraph/how-tos/persistence_postgres/)"
   ],
   "metadata": {
    "id": "9iKKYdAkVoxu"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Lwi6YkLu31aK",
    "ExecuteTime": {
     "end_time": "2025-02-21T13:35:25.395634Z",
     "start_time": "2025-02-21T13:35:21.975997Z"
    }
   },
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langgraph langgraph-checkpoint-postgres psycopg psycopg-pool langchain_google_genai\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraph-checkpoint-postgres\n",
      "  Downloading langgraph_checkpoint_postgres-2.0.15-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting psycopg\n",
      "  Downloading psycopg-3.2.4-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting psycopg-pool\n",
      "  Downloading psycopg_pool-3.2.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.15 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from langgraph-checkpoint-postgres) (2.0.15)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from langgraph-checkpoint-postgres) (3.10.15)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from psycopg) (4.12.2)\n",
      "Collecting tzdata (from psycopg)\n",
      "  Using cached tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.2.38 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (0.3.35)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (1.1.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (0.3.8)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (2.10.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (0.27.0)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (2.27.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (4.6.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (2.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (1.2.0)\n",
      "Downloading langgraph_checkpoint_postgres-2.0.15-py3-none-any.whl (35 kB)\n",
      "Downloading psycopg-3.2.4-py3-none-any.whl (198 kB)\n",
      "Downloading psycopg_pool-3.2.4-py3-none-any.whl (38 kB)\n",
      "Using cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: tzdata, psycopg-pool, psycopg, langgraph-checkpoint-postgres\n",
      "Successfully installed langgraph-checkpoint-postgres-2.0.15 psycopg-3.2.4 psycopg-pool-3.2.4 tzdata-2025.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T13:59:48.748863Z",
     "start_time": "2025-02-21T13:59:44.545145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install psycopg2-binary\n",
    "!pip install langgraph-checkpoint-postgres"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (2.9.10)\n",
      "Requirement already satisfied: langgraph-checkpoint-postgres in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (2.0.15)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.15 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from langgraph-checkpoint-postgres) (2.0.15)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from langgraph-checkpoint-postgres) (3.10.15)\n",
      "Requirement already satisfied: psycopg<4.0.0,>=3.2.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from langgraph-checkpoint-postgres) (3.2.4)\n",
      "Requirement already satisfied: psycopg-pool<4.0.0,>=3.2.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from langgraph-checkpoint-postgres) (3.2.4)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.2.38 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (0.3.35)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from psycopg<4.0.0,>=3.2.0->langgraph-checkpoint-postgres) (4.12.2)\n",
      "Requirement already satisfied: tzdata in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from psycopg<4.0.0,>=3.2.0->langgraph-checkpoint-postgres) (2025.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (0.3.8)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (2.10.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (0.27.0)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (2.27.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (4.6.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (2.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.2.38->langgraph-checkpoint<3.0.0,>=2.0.15->langgraph-checkpoint-postgres) (1.2.0)\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(r\"H:\\My_LangGraph_toturial\\.env\")\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = os.getenv(var)\n",
    "        print(\"var\" , var)\n",
    "        print(\"key\" , os.getenv(var))\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ],
   "metadata": {
    "id": "i6Tn95wS4rxz",
    "ExecuteTime": {
     "end_time": "2025-02-21T14:02:03.551428Z",
     "start_time": "2025-02-21T14:02:03.526882Z"
    }
   },
   "outputs": [],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGCHAIN_API_KEY')\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchain-academy\""
   ],
   "metadata": {
    "id": "qtL0cG1B8pMt",
    "ExecuteTime": {
     "end_time": "2025-02-21T13:52:13.377678Z",
     "start_time": "2025-02-21T13:52:13.346343Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'userdata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLANGCHAIN_API_KEY\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43muserdata\u001B[49m\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLANGCHAIN_API_KEY\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      3\u001B[0m os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLANGCHAIN_TRACING_V2\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrue\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      4\u001B[0m os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLANGCHAIN_PROJECT\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlangchain-academy\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'userdata' is not defined"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T13:55:27.179107Z",
     "start_time": "2025-02-21T13:55:24.984341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install psycopg2-binary python-dotenv\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (2.9.10)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\talib\\miniconda3\\envs\\panaversity\\lib\\site-packages (1.0.1)\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Use sync connection¶\n",
    "This sets up a synchronous connection to the database.\n",
    "\n",
    "Synchronous connections execute operations in a blocking manner, meaning each operation waits for completion before moving to the next one. The DB_URI is the database connection URI, with the protocol used for connecting to a PostgreSQL database, authentication, and host where database is running. The connection_kwargs dictionary defines additional parameters for the database connection."
   ],
   "metadata": {
    "id": "AqAjciKmV6vl"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "from psycopg2 import pool\n",
    "from dotenv import load_dotenv\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "# create a database in https://neon.tech/ , take the URI and and paste it in .env file\n",
    "load_dotenv(r\"H:\\My_LangGraph_toturial\\.env\")\n",
    "DB_URI :str = os.getenv(\"DB_URI\")\n",
    "print(DB_URI)\n",
    "# Create a connection pool\n",
    "connection_pool = pool.SimpleConnectionPool(\n",
    "    1,  # Minimum number of connections in the pool\n",
    "    10,  # Maximum number of connections in the pool\n",
    "    DB_URI\n",
    ")\n",
    "# Check if the pool was created successfully\n",
    "if connection_pool:\n",
    "    print(\"Connection pool created successfully\")\n",
    "# Get a connection from the pool\n",
    "# Initialize PostgresSaver checkpointer\n",
    "# checkpointer = PostgresSaver(connection_pool)\n",
    "# checkpointer.setup()\n",
    "# Create a cursor object\n",
    "\n"
   ],
   "metadata": {
    "id": "cP2TdPSB3-dO",
    "ExecuteTime": {
     "end_time": "2025-02-21T14:02:06.388447Z",
     "start_time": "2025-02-21T14:02:06.215171Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "no pq wrapper available.\nAttempts made:\n- couldn't import psycopg 'c' implementation: No module named 'psycopg_c'\n- couldn't import psycopg 'binary' implementation: No module named 'psycopg_binary'\n- couldn't import psycopg 'python' implementation: expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[48], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpsycopg2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pool\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdotenv\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_dotenv\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlanggraph\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcheckpoint\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpostgres\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PostgresSaver\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# create a database in https://neon.tech/ , take the URI and and paste it in .env file\u001B[39;00m\n\u001B[0;32m      6\u001B[0m load_dotenv(\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mH:\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mMy_LangGraph_toturial\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m.env\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\panaversity\\lib\\site-packages\\langgraph\\checkpoint\\postgres\\__init__.py:7\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Any, Optional\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_core\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrunnables\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m RunnableConfig\n\u001B[1;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpsycopg\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Capabilities, Connection, Cursor, Pipeline\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpsycopg\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrows\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DictRow, dict_row\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpsycopg\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtypes\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mjson\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Jsonb\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\panaversity\\lib\\site-packages\\psycopg\\__init__.py:9\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# Copyright (C) 2020 The Psycopg Team\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mlogging\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pq  \u001B[38;5;66;03m# noqa: F401 import early to stabilize side effects\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m types\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m postgres\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\panaversity\\lib\\site-packages\\psycopg\\pq\\__init__.py:117\u001B[0m\n\u001B[0;32m    108\u001B[0m         sattempts \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattempt\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m attempt \u001B[38;5;129;01min\u001B[39;00m attempts)\n\u001B[0;32m    109\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[0;32m    110\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\u001B[38;5;130;01m\\\u001B[39;00m\n\u001B[0;32m    111\u001B[0m \u001B[38;5;124mno pq wrapper available.\u001B[39m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;124mAttempts made:\u001B[39m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;132;01m{\u001B[39;00msattempts\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m    114\u001B[0m         )\n\u001B[1;32m--> 117\u001B[0m \u001B[43mimport_from_libpq\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    119\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    120\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConnStatus\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPipelineStatus\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    136\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mversion_pretty\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    137\u001B[0m )\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\panaversity\\lib\\site-packages\\psycopg\\pq\\__init__.py:109\u001B[0m, in \u001B[0;36mimport_from_libpq\u001B[1;34m()\u001B[0m\n\u001B[0;32m    107\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    108\u001B[0m         sattempts \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattempt\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m attempt \u001B[38;5;129;01min\u001B[39;00m attempts)\n\u001B[1;32m--> 109\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[0;32m    110\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\u001B[38;5;130;01m\\\u001B[39;00m\n\u001B[0;32m    111\u001B[0m \u001B[38;5;124mno pq wrapper available.\u001B[39m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;124mAttempts made:\u001B[39m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;132;01m{\u001B[39;00msattempts\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m    114\u001B[0m         )\n",
      "\u001B[1;31mImportError\u001B[0m: no pq wrapper available.\nAttempts made:\n- couldn't import psycopg 'c' implementation: No module named 'psycopg_c'\n- couldn't import psycopg 'binary' implementation: No module named 'psycopg_binary'\n- couldn't import psycopg 'python' implementation: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "source": [
    "from psycopg_pool import ConnectionPool\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "# create a database in https://neon.tech/ , take the URI and and paste it in .env file\n",
    "\n",
    "# Connection pool for efficient database access\n",
    "connection_kwargs = {\"autocommit\": True, \"prepare_threshold\": 0}\n",
    "\n",
    "# Create a persistent connection pool\n",
    "pool = ConnectionPool(conninfo=DB_URI, max_size=20, kwargs=connection_kwargs)\n",
    "\n",
    "# Initialize PostgresSaver checkpointer\n",
    "checkpointer = PostgresSaver(pool)\n",
    "checkpointer.setup()  # Ensure database tables are set up\n"
   ],
   "metadata": {
    "id": "0XCqHjWM4LTc",
    "ExecuteTime": {
     "end_time": "2025-02-21T13:54:52.714212Z",
     "start_time": "2025-02-21T13:54:52.547476Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "no pq wrapper available.\nAttempts made:\n- couldn't import psycopg 'c' implementation: No module named 'psycopg_c'\n- couldn't import psycopg 'binary' implementation: No module named 'psycopg_binary'\n- couldn't import psycopg 'python' implementation: expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[27], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpsycopg_pool\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ConnectionPool\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlanggraph\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcheckpoint\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpostgres\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PostgresSaver\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# create a database in https://neon.tech/ , take the URI and and paste it in .env file\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# Connection pool for efficient database access\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\panaversity\\lib\\site-packages\\psycopg_pool\\__init__.py:7\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;124;03mpsycopg connection pool package\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# Copyright (C) 2021 The Psycopg Team\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpool\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ConnectionPool\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpool_async\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AsyncConnectionPool\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnull_pool\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m NullConnectionPool\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\panaversity\\lib\\site-packages\\psycopg_pool\\pool.py:22\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mweakref\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ref\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcontextlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m contextmanager\n\u001B[1;32m---> 22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpsycopg\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m errors \u001B[38;5;28;01mas\u001B[39;00m e\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpsycopg\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Connection\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpsycopg\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpq\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TransactionStatus\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\panaversity\\lib\\site-packages\\psycopg\\__init__.py:9\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# Copyright (C) 2020 The Psycopg Team\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mlogging\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pq  \u001B[38;5;66;03m# noqa: F401 import early to stabilize side effects\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m types\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m postgres\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\panaversity\\lib\\site-packages\\psycopg\\pq\\__init__.py:117\u001B[0m\n\u001B[0;32m    108\u001B[0m         sattempts \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattempt\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m attempt \u001B[38;5;129;01min\u001B[39;00m attempts)\n\u001B[0;32m    109\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[0;32m    110\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\u001B[38;5;130;01m\\\u001B[39;00m\n\u001B[0;32m    111\u001B[0m \u001B[38;5;124mno pq wrapper available.\u001B[39m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;124mAttempts made:\u001B[39m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;132;01m{\u001B[39;00msattempts\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m    114\u001B[0m         )\n\u001B[1;32m--> 117\u001B[0m \u001B[43mimport_from_libpq\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    119\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    120\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConnStatus\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPipelineStatus\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    136\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mversion_pretty\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    137\u001B[0m )\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\panaversity\\lib\\site-packages\\psycopg\\pq\\__init__.py:109\u001B[0m, in \u001B[0;36mimport_from_libpq\u001B[1;34m()\u001B[0m\n\u001B[0;32m    107\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    108\u001B[0m         sattempts \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m- \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattempt\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m attempt \u001B[38;5;129;01min\u001B[39;00m attempts)\n\u001B[1;32m--> 109\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[0;32m    110\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\u001B[38;5;130;01m\\\u001B[39;00m\n\u001B[0;32m    111\u001B[0m \u001B[38;5;124mno pq wrapper available.\u001B[39m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;124mAttempts made:\u001B[39m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;132;01m{\u001B[39;00msattempts\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m    114\u001B[0m         )\n",
      "\u001B[1;31mImportError\u001B[0m: no pq wrapper available.\nAttempts made:\n- couldn't import psycopg 'c' implementation: No module named 'psycopg_c'\n- couldn't import psycopg 'binary' implementation: No module named 'psycopg_binary'\n- couldn't import psycopg 'python' implementation: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's re-define our chatbot."
   ],
   "metadata": {
    "id": "w9All8mCV1o0"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "\n",
    "from langgraph.graph import END\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "model: ChatGoogleGenerativeAI = ChatGoogleGenerativeAI(model = \"gemini-1.5-flash\", api_key =  GEMINI_API_KEY)\n",
    "\n",
    "class State(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "# Define the logic to call the model\n",
    "def call_model(state: State) -> State:\n",
    "\n",
    "    # Get summary if it exists\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "    print(f\"Using summary: {summary}\")\n",
    "\n",
    "    # If there is summary, then we add it\n",
    "    if summary:\n",
    "\n",
    "        # Add summary to system message\n",
    "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "\n",
    "        # Append summary to any newer messages\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "\n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "\n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def summarize_conversation(state: State) -> State:\n",
    "    print(f\"Messages before summarizing: {len(state['messages'])}\")\n",
    "    # First, we get any existing summary\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "    print(f\"Existing summary: {summary}\")\n",
    "\n",
    "    # Create our summarization prompt\n",
    "    if summary:\n",
    "\n",
    "        # A summary already exists\n",
    "        summary_message = (\n",
    "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
    "            \"Extend the summary by taking into account the new messages above:\"\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        summary_message = \"Create a summary of the conversation above:\"\n",
    "\n",
    "\n",
    "    # Add prompt to our history\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    response = model.invoke(messages)\n",
    "    # Summarization logic\n",
    "    print(f\"New summary: {response.content}\")\n",
    "\n",
    "    # Delete all but the 2 most recent messages\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "\n",
    "    print(f\"Messages after truncation: {len(delete_messages)}\")\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}\n",
    "\n",
    "# Determine whether to end or summarize the conversation\n",
    "def should_continue(state: State) -> State:\n",
    "\n",
    "    \"\"\"Return the next node to execute.\"\"\"\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    print(f\"Message count: {len(messages)}\")\n",
    "    # If there are more than six messages, then we summarize the conversation\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "\n",
    "    # Otherwise we can just end\n",
    "    return END"
   ],
   "metadata": {
    "id": "kvU-4FnS4Wxu"
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we just re-compile with our postgres checkpointer."
   ],
   "metadata": {
    "id": "zzIVvGsXWap4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "\n",
    "# Redefine workflow\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"conversation\", call_model)\n",
    "workflow.add_node(summarize_conversation)\n",
    "\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# Compile the workflow with PostgreSQL checkpointer\n",
    "graph = workflow.compile(checkpointer=checkpointer)\n"
   ],
   "metadata": {
    "id": "d7wrnazV4mdo"
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we can invoke the graph several times."
   ],
   "metadata": {
    "id": "C_KTIXuvWkT0"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Configuration for thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start a conversation\n",
    "input_message = HumanMessage(content=\"hi! I'm Wania\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config)\n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "# Check the persisted state\n",
    "graph_state = graph.get_state(config)\n",
    "graph_state"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wk129iSWZapB",
    "outputId": "15ba3c91-a4a5-4866-dca9-9c3349540f60"
   },
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using summary: \n",
      "Message count: 2\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Hi Wania! It's nice to meet you.  How can I help you today?\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content=\"hi! I'm Wania\", additional_kwargs={}, response_metadata={}, id='d76cb391-15b6-477b-a691-aebb30636879'), AIMessage(content=\"Hi Wania! It's nice to meet you.  How can I help you today?\\n\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-edfffea1-6d53-480d-b547-719e8d8e4d88-0', usage_metadata={'input_tokens': 8, 'output_tokens': 21, 'total_tokens': 29, 'input_token_details': {'cache_read': 0}})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efa90f2-806a-658e-8001-e28bcb3c1e39'}}, metadata={'step': 1, 'source': 'loop', 'writes': {'conversation': {'messages': AIMessage(content=\"Hi Wania! It's nice to meet you.  How can I help you today?\\n\", additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'safety_ratings': [], 'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}}, id='run-edfffea1-6d53-480d-b547-719e8d8e4d88-0', usage_metadata={'input_tokens': 8, 'output_tokens': 21, 'total_tokens': 29, 'input_token_details': {'cache_read': 0}})}}, 'parents': {}, 'thread_id': '1'}, created_at='2024-11-22T20:20:03.290218+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efa90f2-7ace-66ef-8000-9a624abe57a3'}}, tasks=())"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Configuration for thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start a conversation\n",
    "input_message = HumanMessage(content=\"I like painting pictures.\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config)\n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "# Check the persisted state\n",
    "graph_state = graph.get_state(config)\n",
    "graph_state"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HxWCVPkuZvf-",
    "outputId": "7df97126-f3c9-46d6-8e26-c33b05bba79b"
   },
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using summary: \n",
      "Message count: 4\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "That's wonderful!  What kind of pictures do you like to paint?  Do you have a favorite medium (like oils, acrylics, watercolors)?\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content=\"hi! I'm Wania\", additional_kwargs={}, response_metadata={}, id='d76cb391-15b6-477b-a691-aebb30636879'), AIMessage(content=\"Hi Wania! It's nice to meet you.  How can I help you today?\\n\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-edfffea1-6d53-480d-b547-719e8d8e4d88-0', usage_metadata={'input_tokens': 8, 'output_tokens': 21, 'total_tokens': 29, 'input_token_details': {'cache_read': 0}}), HumanMessage(content='I like painting pictures.', additional_kwargs={}, response_metadata={}, id='523173cf-f888-4141-9cde-66160074c905'), AIMessage(content=\"That's wonderful!  What kind of pictures do you like to paint?  Do you have a favorite medium (like oils, acrylics, watercolors)?\\n\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-d32dc7af-09a0-427c-a9e6-a06d79487552-0', usage_metadata={'input_tokens': 36, 'output_tokens': 34, 'total_tokens': 70, 'input_token_details': {'cache_read': 0}})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efa90f2-b844-6011-8004-b7f28420f319'}}, metadata={'step': 4, 'source': 'loop', 'writes': {'conversation': {'messages': AIMessage(content=\"That's wonderful!  What kind of pictures do you like to paint?  Do you have a favorite medium (like oils, acrylics, watercolors)?\\n\", additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'safety_ratings': [], 'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}}, id='run-d32dc7af-09a0-427c-a9e6-a06d79487552-0', usage_metadata={'input_tokens': 36, 'output_tokens': 34, 'total_tokens': 70, 'input_token_details': {'cache_read': 0}})}}, 'parents': {}, 'thread_id': '1'}, created_at='2024-11-22T20:20:09.146534+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efa90f2-b27a-6779-8003-2a8720cf1fba'}}, tasks=())"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Configuration for thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start a conversation\n",
    "input_message = HumanMessage(content=\"What's my name and what is my hobby?\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config)\n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "# Check the persisted state\n",
    "graph_state = graph.get_state(config)\n",
    "graph_state"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HxLLjBiBfZAL",
    "outputId": "b589d8ae-6302-41aa-bd0b-953dca9bfa69"
   },
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using summary: \n",
      "Message count: 6\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Your name is Wania, and your hobby is painting pictures.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content=\"hi! I'm Wania\", additional_kwargs={}, response_metadata={}, id='d76cb391-15b6-477b-a691-aebb30636879'), AIMessage(content=\"Hi Wania! It's nice to meet you.  How can I help you today?\\n\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-edfffea1-6d53-480d-b547-719e8d8e4d88-0', usage_metadata={'input_tokens': 8, 'output_tokens': 21, 'total_tokens': 29, 'input_token_details': {'cache_read': 0}}), HumanMessage(content='I like painting pictures.', additional_kwargs={}, response_metadata={}, id='523173cf-f888-4141-9cde-66160074c905'), AIMessage(content=\"That's wonderful!  What kind of pictures do you like to paint?  Do you have a favorite medium (like oils, acrylics, watercolors)?\\n\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-d32dc7af-09a0-427c-a9e6-a06d79487552-0', usage_metadata={'input_tokens': 36, 'output_tokens': 34, 'total_tokens': 70, 'input_token_details': {'cache_read': 0}}), HumanMessage(content=\"What's my name and what is my hobby?\", additional_kwargs={}, response_metadata={}, id='776f97d7-ab33-4746-9676-b3dfdfdaa4c9'), AIMessage(content='Your name is Wania, and your hobby is painting pictures.\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-02fd8b76-b4e6-4a71-be86-0e7af1190e26-0', usage_metadata={'input_tokens': 83, 'output_tokens': 14, 'total_tokens': 97, 'input_token_details': {'cache_read': 0}})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efa90f3-3353-61b1-8007-621aaf4234ba'}}, metadata={'step': 7, 'source': 'loop', 'writes': {'conversation': {'messages': AIMessage(content='Your name is Wania, and your hobby is painting pictures.\\n', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'safety_ratings': [], 'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}}, id='run-02fd8b76-b4e6-4a71-be86-0e7af1190e26-0', usage_metadata={'input_tokens': 83, 'output_tokens': 14, 'total_tokens': 97, 'input_token_details': {'cache_read': 0}})}}, 'parents': {}, 'thread_id': '1'}, created_at='2024-11-22T20:20:22.050221+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efa90f3-2fbc-6989-8006-756336db15f2'}}, tasks=())"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Configuration for thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start a conversation\n",
    "input_message = HumanMessage(content=\"Can you describe about abstract paintings?\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config)\n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "# Check the persisted state\n",
    "graph_state = graph.get_state(config)\n",
    "graph_state"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iygDZ-_xhsQW",
    "outputId": "0a6afef6-7459-4f8e-8a96-01801d2db6be"
   },
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using summary: \n",
      "Message count: 8\n",
      "Messages before summarizing: 8\n",
      "Existing summary: \n",
      "New summary: The conversation began with introductions, where I learned the user's name is Wania and her hobby is painting.  We then discussed abstract painting, with me providing a description of its characteristics, including its non-representational nature, emphasis on form and color, expressive qualities, stylistic variety, and subjective interpretation.\n",
      "\n",
      "Messages after truncation: 6\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Abstract painting is a genre of art that doesn't attempt to represent an accurate depiction of visual reality but instead uses shapes, colors, forms, and gestural marks to achieve its effect.  It prioritizes expressing feelings, ideas, or concepts rather than depicting objects recognizably.\n",
      "\n",
      "Here are some key characteristics of abstract painting:\n",
      "\n",
      "* **Non-representational:**  Unlike realistic or figurative art, abstract art doesn't aim to portray a specific person, place, or thing in a recognizable way.\n",
      "\n",
      "* **Emphasis on form and color:** The focus shifts to the interplay of shapes, lines, colors, and textures.  These elements are used to create visual interest and evoke emotions.\n",
      "\n",
      "* **Expressiveness:** Abstract art often aims to convey emotions, moods, or ideas directly through the visual language of the painting.\n",
      "\n",
      "* **Variety of styles:** Abstract art encompasses a wide range of styles, including:\n",
      "    * **Geometric abstraction:** Uses geometric shapes and forms.\n",
      "    * **Lyrical abstraction:** Emphasizes fluidity and emotional expression.\n",
      "    * **Gestural abstraction:** Focuses on the physical act of painting and the artist's movement.\n",
      "    * **Color field painting:**  Uses large areas of flat color to create mood and atmosphere.\n",
      "\n",
      "* **Subjectivity:** The meaning and interpretation of an abstract painting are often subjective and open to the viewer's own experience and perspective. There's no single \"correct\" interpretation.\n",
      "\n",
      "\n",
      "Abstract art can be challenging to understand at first, but its beauty lies in its freedom from representational constraints and its ability to evoke powerful emotions and thoughts through pure visual expression.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Can you describe about abstract paintings?', additional_kwargs={}, response_metadata={}, id='87c170ad-ffa1-415f-b652-d2d7cd6d3b77'), AIMessage(content='Abstract painting is a genre of art that doesn\\'t attempt to represent an accurate depiction of visual reality but instead uses shapes, colors, forms, and gestural marks to achieve its effect.  It prioritizes expressing feelings, ideas, or concepts rather than depicting objects recognizably.\\n\\nHere are some key characteristics of abstract painting:\\n\\n* **Non-representational:**  Unlike realistic or figurative art, abstract art doesn\\'t aim to portray a specific person, place, or thing in a recognizable way.\\n\\n* **Emphasis on form and color:** The focus shifts to the interplay of shapes, lines, colors, and textures.  These elements are used to create visual interest and evoke emotions.\\n\\n* **Expressiveness:** Abstract art often aims to convey emotions, moods, or ideas directly through the visual language of the painting.\\n\\n* **Variety of styles:** Abstract art encompasses a wide range of styles, including:\\n    * **Geometric abstraction:** Uses geometric shapes and forms.\\n    * **Lyrical abstraction:** Emphasizes fluidity and emotional expression.\\n    * **Gestural abstraction:** Focuses on the physical act of painting and the artist\\'s movement.\\n    * **Color field painting:**  Uses large areas of flat color to create mood and atmosphere.\\n\\n* **Subjectivity:** The meaning and interpretation of an abstract painting are often subjective and open to the viewer\\'s own experience and perspective. There\\'s no single \"correct\" interpretation.\\n\\n\\nAbstract art can be challenging to understand at first, but its beauty lies in its freedom from representational constraints and its ability to evoke powerful emotions and thoughts through pure visual expression.\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-24c68d6c-3368-4a5f-8550-f5f9c19a095b-0', usage_metadata={'input_tokens': 106, 'output_tokens': 336, 'total_tokens': 442, 'input_token_details': {'cache_read': 0}})], 'summary': \"The conversation began with introductions, where I learned the user's name is Wania and her hobby is painting.  We then discussed abstract painting, with me providing a description of its characteristics, including its non-representational nature, emphasis on form and color, expressive qualities, stylistic variety, and subjective interpretation.\\n\"}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efa90f3-b899-65b2-800b-746b642dd23e'}}, metadata={'step': 11, 'source': 'loop', 'writes': {'summarize_conversation': {'summary': \"The conversation began with introductions, where I learned the user's name is Wania and her hobby is painting.  We then discussed abstract painting, with me providing a description of its characteristics, including its non-representational nature, emphasis on form and color, expressive qualities, stylistic variety, and subjective interpretation.\\n\", 'messages': [RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='d76cb391-15b6-477b-a691-aebb30636879'), RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='run-edfffea1-6d53-480d-b547-719e8d8e4d88-0'), RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='523173cf-f888-4141-9cde-66160074c905'), RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='run-d32dc7af-09a0-427c-a9e6-a06d79487552-0'), RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='776f97d7-ab33-4746-9676-b3dfdfdaa4c9'), RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='run-02fd8b76-b4e6-4a71-be86-0e7af1190e26-0')]}}, 'parents': {}, 'thread_id': '1'}, created_at='2024-11-22T20:20:36.025050+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efa90f3-b1d4-68fa-800a-fbd02f0297f6'}}, tasks=())"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "gFqFzWDrWnt5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Retrieve state using thread ID\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "graph_state = graph.get_state(config)\n",
    "graph_state"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cmwlf-TFYQqH",
    "outputId": "535362f8-27ba-438d-853f-252e58dbb4dc"
   },
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Can you describe about abstract paintings?', additional_kwargs={}, response_metadata={}, id='87c170ad-ffa1-415f-b652-d2d7cd6d3b77'), AIMessage(content='Abstract painting is a genre of art that doesn\\'t attempt to represent an accurate depiction of visual reality but instead uses shapes, colors, forms, and gestural marks to achieve its effect.  It prioritizes expressing feelings, ideas, or concepts rather than depicting objects recognizably.\\n\\nHere are some key characteristics of abstract painting:\\n\\n* **Non-representational:**  Unlike realistic or figurative art, abstract art doesn\\'t aim to portray a specific person, place, or thing in a recognizable way.\\n\\n* **Emphasis on form and color:** The focus shifts to the interplay of shapes, lines, colors, and textures.  These elements are used to create visual interest and evoke emotions.\\n\\n* **Expressiveness:** Abstract art often aims to convey emotions, moods, or ideas directly through the visual language of the painting.\\n\\n* **Variety of styles:** Abstract art encompasses a wide range of styles, including:\\n    * **Geometric abstraction:** Uses geometric shapes and forms.\\n    * **Lyrical abstraction:** Emphasizes fluidity and emotional expression.\\n    * **Gestural abstraction:** Focuses on the physical act of painting and the artist\\'s movement.\\n    * **Color field painting:**  Uses large areas of flat color to create mood and atmosphere.\\n\\n* **Subjectivity:** The meaning and interpretation of an abstract painting are often subjective and open to the viewer\\'s own experience and perspective. There\\'s no single \"correct\" interpretation.\\n\\n\\nAbstract art can be challenging to understand at first, but its beauty lies in its freedom from representational constraints and its ability to evoke powerful emotions and thoughts through pure visual expression.\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-24c68d6c-3368-4a5f-8550-f5f9c19a095b-0', usage_metadata={'input_tokens': 106, 'output_tokens': 336, 'total_tokens': 442, 'input_token_details': {'cache_read': 0}})], 'summary': \"The conversation began with introductions, where I learned the user's name is Wania and her hobby is painting.  We then discussed abstract painting, with me providing a description of its characteristics, including its non-representational nature, emphasis on form and color, expressive qualities, stylistic variety, and subjective interpretation.\\n\"}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efa90f3-b899-65b2-800b-746b642dd23e'}}, metadata={'step': 11, 'source': 'loop', 'writes': {'summarize_conversation': {'summary': \"The conversation began with introductions, where I learned the user's name is Wania and her hobby is painting.  We then discussed abstract painting, with me providing a description of its characteristics, including its non-representational nature, emphasis on form and color, expressive qualities, stylistic variety, and subjective interpretation.\\n\", 'messages': [RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='d76cb391-15b6-477b-a691-aebb30636879'), RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='run-edfffea1-6d53-480d-b547-719e8d8e4d88-0'), RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='523173cf-f888-4141-9cde-66160074c905'), RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='run-d32dc7af-09a0-427c-a9e6-a06d79487552-0'), RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='776f97d7-ab33-4746-9676-b3dfdfdaa4c9'), RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='run-02fd8b76-b4e6-4a71-be86-0e7af1190e26-0')]}}, 'parents': {}, 'thread_id': '1'}, created_at='2024-11-22T20:20:36.025050+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efa90f3-b1d4-68fa-800a-fbd02f0297f6'}}, tasks=())"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "pool.close()"
   ],
   "metadata": {
    "id": "d_YbgTBs89_o"
   },
   "execution_count": 62,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Persisting state\n",
    "\n",
    "Using database like Postgres means state is persisted!\n",
    "\n",
    "For example, we can re-start the notebook kernel and see that we can still load from Postgres DB on disk.\n"
   ],
   "metadata": {
    "id": "Io-K7MCWinYF"
   }
  }
 ]
}
